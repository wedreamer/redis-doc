---
title: Redis cluster specification
linkTitle: Cluster spec
weight: 1
description: >
    Detailed specification for Redis cluster
aliases:
  - /topics/cluster-spec
---

欢迎来到**Redis 集群规范**.在这里，您将找到信息
关于 Redis Cluster 的算法和设计原理。本文档是一部作品
正在进行中，因为它与实际实施不断同步
的雷迪斯。

## 设计的主要特性和基本原理

### Redis 集群目标

Redis Cluster 是 Redis 的分布式实现，其目标在设计中的重要性排序如下：

*   高性能和线性可扩展性，最多可达 1000 个节点。没有代理，使用异步复制，并且不对值执行任何合并操作。
*   可接受的写入安全程度：系统尝试（以最佳方式）保留来自与大多数主节点连接的客户端的所有写入。通常有一些小窗口，其中确认的写入可能会丢失。当客户端位于少数分区中时，丢失已确认写入的窗口会更大。
*   可用性：Redis 集群能够在大多数主节点可访问的分区中生存，并且每个不再可访问的主节点至少有一个可访问的副本。此外，使用*副本迁移*，则不再由任何副本复制的主节点将从多个副本覆盖的主服务器接收一个副本。

本文档中描述的内容在 Redis 3.0 或更高版本中实现。

### 已实现的子集

Redis 集群实现了
Redis 的非分布式版本。执行复杂多键的命令
诸如集合并集和交集之类的操作适用于以下情况：
操作中涉及的所有密钥都散列到同一插槽。

Redis Cluster 实现了一个概念，称为**哈希标签**可以使用
以强制将某些密钥存储在同一哈希槽中。但是，在
手动重新分片，多键操作可能会在一段时间内不可用
而单键操作始终可用。

Redis 集群不支持像独立版本那样的多个数据库
的雷迪斯。我们只支持数据库`0`;这`SELECT`命令是不允许的。

## Redis 群集协议中的客户端和服务器角色

在 Redis 集群中，节点负责保存数据，
并获取群集的状态，包括将密钥映射到正确的节点。
群集节点还能够自动发现其他节点，检测不工作
节点，并在需要时按顺序将副本节点提升为主节点
以在发生故障时继续运行。

要执行其任务，所有群集节点都使用
TCP 总线和二进制协议，称为**Redis Cluster Bus**.
每个节点都使用群集连接到群集中的每个其他节点
总线。节点使用八卦协议来传播有关群集的信息
为了发现新节点，发送ping数据包以确保所有
其他节点工作正常，并且要发送群集消息需要
信号特定条件。群集总线还用于
在群集中传播发布/订阅消息并编排手动
用户请求时的故障转移（手动故障转移是
不是由 Redis 群集故障检测器启动的，而是由
直接系统管理员）。

由于群集节点无法代理请求，因此可能会重定向客户端
使用重定向错误到其他节点`-MOVED`和`-ASK`.
从理论上讲，客户端可以自由地向集群中的所有节点发送请求，
如果需要，将重定向，因此客户端不需要持有
群集的状态。但是，能够在
键和节点可以以合理的方式提高性能。

### 写入安全

Redis 集群使用节点之间的异步复制，并且**上次故障转移获胜**隐式合并函数。这意味着最后一个选择的主数据集最终会替换所有其他副本。在分区期间，始终存在一个可能丢失写入的时间窗口。但是，在连接到大多数主节点的客户端和连接到少数主节点的客户端的情况下，这些窗口非常不同。

与少数端执行的写入相比，Redis 集群会更努力地保留由连接到大多数主服务器的客户端执行的写入操作。
以下是导致已确认丢失的场景示例
在故障期间在大多数分区中接收的写入操作：

1.  写入操作可能会到达主节点，但虽然主节点可能能够回复客户端，但写入操作可能无法通过主节点和副本节点之间使用的异步复制传播到副本。如果主服务器在写操作未到达副本的情况下死亡，则如果主服务器无法访问的时间足够长，以至于其一个副本被提升，则写入操作将永远丢失。在主节点完全突然发生故障的情况下，通常很难观察到这一点，因为主节点尝试同时回复客户端（通过写入确认）和副本（传播写入）。然而，这是一种现实世界的故障模式。

2.  另一种理论上可能的故障模式是：以下几种情况：

*   由于分区，无法访问主服务器。
*   它被其副本之一故障转移。
*   一段时间后，它可能会再次到达。
*   具有过期路由表的客户端可能会在群集转换为（新主数据库）副本之前写入旧主服务器。

第二种故障模式不太可能发生，因为无法在足够的时间内与大多数其他主节点通信以进行故障转移，并且当分区固定时，写入仍会被拒绝一小段时间，以允许其他节点通知配置更改。此故障模式还要求客户端的路由表尚未更新。

针对分区少数端的写入具有更大的窗口，可以在其中迷失方向。例如，Redis 集群在分区上丢失了不平凡的写入次数，其中有少数主节点和至少一个或多个客户端，因为如果主服务器在多数端进行故障转移，则发送到主服务器的所有写入操作都可能丢失。

具体来说，对于要故障转移的主节点，大多数主节点至少无法访问它`NODE_TIMEOUT`，因此，如果分区在该时间之前已修复，则不会丢失任何写入操作。当分区持续时间超过`NODE_TIMEOUT`，到目前为止，在少数方执行的所有写入操作都可能丢失。但是，Redis集群的少数派将立即开始拒绝写入`NODE_TIMEOUT`在没有与多数人接触的情况下，时间已经过去了，因此有一个最大的窗口，在此窗口之后，少数人将不再可用。因此，在此之后，不会接受或丢失任何写入。

### 可用性

Redis 集群在分区的少数端不可用。在分区的大多数端，假设每个无法访问的主服务器至少有大多数主服务器和一个副本，则群集在以下时间后再次变为可用`NODE_TIMEOUT`时间加上复制副本需要几秒钟才能当选并对其主节点进行故障转移（故障转移通常在 1 或 2 秒内执行）。

这意味着 Redis 集群旨在经受住集群中几个节点的故障，但对于在发生大型网络拆分时需要可用性的应用程序来说，它不是合适的解决方案。

在由 N 个主节点组成的集群示例中，其中每个节点都有一个副本，只要将单个节点分区，集群的大多数端将保持可用，并且将保持可用，概率为`1-(1/(N*2-1))`当两个节点被分割开来时（在第一个节点发生故障后，我们剩下`N*2-1`节点总数，唯一没有副本的主节点失败的概率为`1/(N*2-1))`.

例如，在具有 5 个节点且每个节点只有一个副本的群集中，有一个`1/(5*2-1) = 11.11%`在将两个节点从多数节点分区后，群集将不再可用。

多亏了 Redis Cluster 的特性，该特性称为**副本迁移**集群
在许多现实世界的场景中，可用性得到了提高，因为
副本迁移到孤立的主节点（主节点不再具有副本）。
因此，在每次成功的故障事件中，群集都可能重新配置副本
布局，以便更好地抵抗下一次故障。

### 性能

在 Redis 群集中，节点不会将命令代理给负责给定密钥的正确节点，而是将客户端重定向到为密钥空间的给定部分提供服务的正确节点。

最终，客户端将获得群集的最新表示形式以及哪个节点为哪些密钥子集提供服务，因此在正常操作期间，客户端直接联系正确的节点以发送给定的命令。

由于使用了异步复制，节点不会等待其他节点确认写入（如果未使用`WAIT`命令）。

此外，由于多键命令仅限于*近*键，则数据永远不会在节点之间移动，除非重新分片。

正常操作的处理方式与单个 Redis 实例完全相同。这意味着，在具有 N 个主节点的 Redis 集群中，随着设计线性扩展，您可以期望获得与单个 Redis 实例乘以 N 相同的性能。同时，查询通常在单个往返行程中执行，因为客户端通常保留与节点的持久连接，因此延迟数字也与单个独立 Redis 节点的情况相同。

非常高的性能和可扩展性，同时保持弱但
合理形式的数据安全和可用性是
Redis Cluster.

### 为什么避免合并操作

Redis 集群设计避免了多个节点中同一键值对的冲突版本，这与 Redis 数据模型的情况一样，并不总是可取的。Redis中的值通常非常大;通常可以看到包含数百万个元素的列表或排序集。此外，数据类型在语义上也很复杂。传输和合并这些类型的值可能是一个主要瓶颈和/或可能需要应用程序端逻辑的不平凡参与、存储元数据的额外内存等。

这里没有严格的技术限制。CRDT 或同步复制
状态机可以对类似于 Redis 的复杂数据类型进行建模。但是，
此类系统的实际运行时行为与 Redis 集群不同。
Redis Cluster 旨在涵盖
非集群 Redis 版本。

## Redis 集群主要组件概述

### 密钥分发模型

群集的密钥空间被拆分为 16384 个插槽，有效地设置了上限
对于 16384 个主节点的集群大小（但是，建议的最大大小为
节点的数量约为 1000 个节点）。

集群中的每个主节点处理 16384 个哈希槽的子集。
群集是**稳定**当 中没有群集重新配置时
进度（即哈希槽从一个节点移动到另一个节点的位置）。
当集群稳定时，单个哈希槽将由单个节点提供服务
（但是，服务节点可以有一个或多个副本，这些副本将在网络拆分或故障的情况下替换它，
并且可用于扩展读取操作，其中读取过时数据是可以接受的）。

用于将密钥映射到哈希槽的基本算法如下
（阅读此规则的哈希标记例外的下一段）：

    HASH_SLOT = CRC16(key) mod 16384

CRC16 的指定如下：

*   名称：XMODEM（也称为ZMODEM或CRC-16 / ACORN）
*   宽度：16 位
*   Poly：1021（实际上是 x^16 + x^12 + x^5 + 1）
*   初始化：0000
*   反射输入字节：假
*   反射输出CRC：假
*   输出CRC的Xor常数：0000
*   “123456789”输出：31C3

使用16个CRC16输出位中的14个（这就是为什么有
上述公式中的模数 16384 运算）。

在我们的测试中，CRC16在分配不同种类的
键均匀地穿过 16384 插槽。

**注意**：所用CRC16算法的参考实现可在本文档的附录A中找到。

### 哈希标签

按顺序使用的哈希槽的计算有一个例外
实施**哈希标签**.哈希标签是确保多个键的一种方法
分配在同一哈希槽中。这是为了实现
Redis 集群中的多键操作。

要实现哈希标记，密钥的哈希槽在
在某些条件下略有不同。
如果密钥包含“{...}”模式，则只有
`{`和`}`进行哈希处理以获取哈希槽。但是，由于它是
可能存在多次`{`或`}`算法是
由以下规则很好地指定：

*   如果密钥包含`{`字符。
*   如果有`}`字符到右侧`{`.
*   如果第一次出现的 之间有一个或多个字符`{`和首次出现的`}`.

然后，不是对密钥进行哈希处理，而只是第一次出现`{`和以下第一次出现的`}`是散列的。

例子：

*   两个键`{user1000}.following`和`{user1000}.followers`将哈希到相同的哈希槽，因为只有子字符串`user1000`将进行哈希处理以计算哈希槽。
*   对于密钥`foo{}{bar}`整个密钥将像往常一样进行哈希处理，因为第一次出现`{`后跟`}`在右侧，中间没有字符。
*   对于密钥`foo{{bar}}zap`子字符串`{bar`将被散列，因为它是第一次出现的子字符串`{`和首次出现的`}`在其右侧。
*   对于密钥`foo{bar}{zap}`子字符串`bar`将被散列，因为算法在第一个有效或无效（内部没有字节）匹配时停止`{`和`}`.
*   从算法中得出的结论是，如果密钥以`{}`，则保证将其作为一个整体进行哈希处理。这在使用二进制数据作为键名时很有用。

添加哈希标签异常，下面是一个实现`HASH_SLOT`Ruby 和 C 语言中的函数。

拼音示例代码：

    def HASH_SLOT(key)
        s = key.index "{"
        if s
            e = key.index "}",s+1
            if e && e != s+1
                key = key[s+1..e-1]
            end
        end
        crc16(key) % 16384
    end

C 示例代码：

    unsigned int HASH_SLOT(char *key, int keylen) {
        int s, e; /* start-end indexes of { and } */

        /* Search the first occurrence of '{'. */
        for (s = 0; s < keylen; s++)
            if (key[s] == '{') break;

        /* No '{' ? Hash the whole key. This is the base case. */
        if (s == keylen) return crc16(key,keylen) & 16383;

        /* '{' found? Check if we have the corresponding '}'. */
        for (e = s+1; e < keylen; e++)
            if (key[e] == '}') break;

        /* No '}' or nothing between {} ? Hash the whole key. */
        if (e == keylen || e == s+1) return crc16(key,keylen) & 16383;

        /* If we are here there is both a { and a } on its right. Hash
         * what is in the middle between { and }. */
        return crc16(key+s+1,e-s-1) & 16383;
    }

### 群集节点属性

群集中的每个节点都有一个唯一的名称。节点名称为
160位随机数的十六进制表示，第一次得到一个
node 是启动的（通常使用 /dev/urandom）。
节点将在其 ID 保存在节点配置文件中，并将使用
永远相同的ID，或者至少只要节点配置文件不是
由系统管理员删除，或*硬复位*已请求
通过`CLUSTER RESET`命令。

节点 ID 用于标识整个群集中的每个节点。
给定节点可以在不需要任何需要的情况下更改其IP地址
以同时更改节点 ID。群集还能够检测到更改
在 IP/端口中，并使用在群集上运行的八卦协议重新配置
总线。

节点 ID 不是与每个节点关联的唯一信息，而是
唯一一个始终全球一致的。每个节点还具有
以下一组相关信息相关联。一些信息是关于
此特定节点的群集配置详细信息，并且最终为
在整个群集中保持一致。其他一些信息，如上次
一个被 ping 的节点，而是每个节点的本地节点。

每个节点都维护有关其他节点的以下信息
感知到群集中：节点的节点 ID、IP 和端口，一组
标志，如果节点被标记为`replica`上次
节点被 ping 和上次收到 pong 时，当前
*配置纪元*的节点（在本规范的后面部分解释），
链接状态，最后是提供的哈希槽集。

详细[所有节点字段的说明](https://redis.io/commands/cluster-nodes)在`CLUSTER NODES`文档。

这`CLUSTER NODES`命令可以发送到群集中的任何节点，并根据查询的节点对群集的本地视图提供群集的状态和每个节点的信息。

以下是`CLUSTER NODES`发送给主节点的命令
节点位于包含三个节点的小型群集中。

    $ redis-cli cluster nodes
    d1861060fe6a534d42d8a19aeb36600e18785e04 127.0.0.1:6379 myself - 0 1318428930 1 connected 0-1364
    3886e65cc906bfd9b1f7e7bde468726a052d1dae 127.0.0.1:6380 master - 1318428930 1318428931 2 connected 1365-2729
    d289c575dcbc4bdd2931585fd4339089e461a27d 127.0.0.1:6381 master - 1318428931 1318428931 3 connected 2730-4095

在上面的列表中，不同的字段是按顺序排列的：节点 ID、地址：端口、标志、上次发送的 ping、接收的最后一次 pong、配置 epoch、链路状态、插槽。有关上述字段的详细信息将在我们讨论 Redis Cluster 的特定部分后立即介绍。

### 群集总线

每个 Redis 集群节点都有一个额外的 TCP 端口用于接收
来自其他 Redis 群集节点的传入连接。此端口将通过向数据端口添加 10000 来派生，也可以使用群集端口配置进行指定。

示例 1：

如果 Redis 节点正在侦听端口 6379 上的客户端连接，
并且您没有在 redis.conf 中添加集群端口参数，
群集总线端口 16379 将被打开。

示例 2：

如果 Redis 节点正在侦听端口 6379 上的客户端连接，
并且您在 redis.conf 中设置了群集端口 20000，
将打开群集总线端口 20000。

节点到节点通信仅使用群集总线和
群集总线协议：由帧组成的二进制协议
不同类型和大小。群集总线二进制协议不是
公开记录，因为它不适用于外部软件设备
以使用此协议与 Redis 集群节点通信。但是您可以
通过阅读
`cluster.h`和`cluster.c`文件中的文件。

### 群集拓扑

Redis 集群是一个完整的网格，其中每个节点都使用 TCP 连接与其他每个节点连接。

在由 N 个节点组成的群集中，每个节点都有 N-1 个传出 TCP 连接和 N-1 个传入连接。

这些 TCP 连接始终保持活动状态，而不是按需创建的。
当节点期望 pong 回复以响应群集总线中的 ping 时，在等待足够长的时间将节点标记为无法访问之前，它将尝试
通过从头开始重新连接来刷新与节点的连接。

当 Redis 集群节点形成一个完整的网格时，**节点使用八卦协议和
配置更新机制，以避免交换太多
正常情况下节点之间的消息**，因此消息数
交换不是指数级的。

### 节点握手

节点始终接受群集总线端口上的连接，甚至回复
收到 ping 时，即使 ping 节点不受信任，也会执行 ping 操作。
但是，如果
发送节点不被视为群集的一部分。

一个节点将仅以两种方式接受另一个节点作为群集的一部分：

*   如果节点显示`MEET`消息 （`CLUSTER MEET`命令）。见面消息正好
    像一个`PING`消息，但强制接收方接受节点作为
    群集。节点将发送`MEET`向其他节点发送消息**仅当**系统管理员通过以下命令请求：

    群集满足 IP 端口

*   如果已经受信任的节点会八卦另一个节点，则节点也会将另一个节点注册为群集的一部分。因此，如果A知道B，而B知道C，最终B会向A发送关于C的八卦信息。发生这种情况时，A 会将 C 注册为网络的一部分，并尝试与 C 连接。

这意味着，只要我们加入任何连接的图中的节点，它们最终将自动形成一个完全连接的图。这意味着群集能够自动发现其他节点，但前提是存在由系统管理员强制建立的受信任关系。

此机制使集群更加健壮，但可以防止不同的 Redis 集群在 IP 地址更改或其他网络相关事件后意外混合。

## 重定向和重新分片

### 移动重定向

Redis 客户端可以自由地向集群中的每个节点发送查询，包括
副本节点。节点将分析查询，以及是否可以接受
（即，查询中仅提及一个键，或多个键
提到的都是到同一个哈希槽）它会查找什么
node 负责密钥所属的哈希槽。

如果哈希槽由节点提供服务，则只需处理查询，否则
节点将检查其内部哈希槽到节点映射，并将回复
到具有 MOVED 错误的客户端，如以下示例所示：

    GET x
    -MOVED 3999 127.0.0.1:6381

该错误包括密钥 （3999） 的哈希槽和可以为查询提供服务的实例的终结点：端口。
客户端需要将查询重新发出到指定节点的终结点地址和端口。
端点可以是 IP 地址、主机名，也可以为空（例如`-MOVED 3999 :6380`).
空终结点表示服务器节点具有未知终结点，客户端应将下一个请求发送到与当前请求相同的终结点，但使用提供的端口。

请注意，即使客户端在重新发出查询之前等待了很长时间，
与此同时，群集配置已更改，目标节点
如果哈希槽 3999 现在由
另一个节点。如果所联系的节点没有更新的信息，也会发生同样的情况。

所以虽然从集群的角度来看，节点是由
ID我们试图简化我们的界面，客户端只是显示地图
在哈希槽和由端点：端口对标识的 Redis 节点之间。

客户端不是必需的，但应该尝试记住该哈希槽
3999 由 127.0.0.1：6381 提供服务。这样，一旦新命令需要
可以计算目标密钥的哈希槽，并具有
选择正确节点的机会更大。

另一种方法是仅刷新整个客户端群集布局
使用`CLUSTER SHARDS`或已弃用的`CLUSTER SLOTS`命令
当收到移动重定向时。当遇到重定向时，它会
可能重新配置了多个插槽，而不仅仅是一个，因此正在更新
尽快配置客户端通常是最佳策略。

请注意，当集群稳定时（配置中没有持续的更改），
最终，所有客户端都将获得哈希槽的映射 - >节点，使
集群效率高，客户端直接寻址正确的节点
没有重定向、代理或其他单点故障实体。

客户端**还必须能够处理 -ASK 重定向**所描述的
在本文档的后面部分，否则它不是一个完整的 Redis 集群客户端。

### 实时重新配置

Redis 集群支持在集群时添加和删除节点的功能
正在运行。添加或删除节点被抽象为同一节点
操作：将哈希槽从一个节点移动到另一个节点。这意味着
可以使用相同的基本机制来重新平衡群集，添加
或删除节点，依此类推。

*   若要将新节点添加到群集，请将空节点添加到群集，并将一些哈希槽集从现有节点移动到新节点。
*   若要从群集中删除节点，分配给该节点的哈希槽将移动到其他现有节点。
*   为了重新平衡集群，在节点之间移动一组给定的哈希槽。

该实现的核心是能够移动哈希槽。
从实际的角度来看，哈希槽只是一组密钥，因此
Redis Cluster 在*重新分片*是要从中移动键
一个实例到另一个实例。移动哈希槽意味着移动所有密钥
碰巧哈希到此哈希槽中。

要了解其工作原理，我们需要显示`CLUSTER`子命令
用于操作 Redis 群集节点中的槽转换表。

以下子命令可用（其中其他子命令在这种情况下没有用）：

*   `CLUSTER ADDSLOTS`插槽1 \[插槽2] ...\[插槽N]
*   `CLUSTER DELSLOTS`插槽1 \[插槽2] ...\[插槽N]
*   `CLUSTER ADDSLOTSRANGE`起始插槽1 结束插槽1 \[起始插槽2 结束插槽2] ...\[起始槽 N 结束槽 N]
*   `CLUSTER DELSLOTSRANGE`起始插槽1 结束插槽1 \[起始插槽2 结束插槽2] ...\[起始槽 N 结束槽 N]
*   `CLUSTER SETSLOT`槽节点节点
*   `CLUSTER SETSLOT`插槽迁移节点
*   `CLUSTER SETSLOT`插槽导入节点

前四个命令，`ADDSLOTS`,`DELSLOTS`,`ADDSLOTSRANGE`和`DELSLOTSRANGE`，仅用于分配
（或删除）Redis 节点的插槽。分配一个插槽意味着告诉给定的
主节点，它将负责存储和提供内容
指定的哈希槽。

分配哈希槽后，它们将在整个群集中传播
使用八卦协议，如后面所述
*配置传播*部分。

这`ADDSLOTS`和`ADDSLOTSRANGE`命令通常在创建新集群时使用
从头开始为每个主节点分配所有 16384 哈希的子集
可用插槽。

这`DELSLOTS`和`DELSLOTSRANGE`主要用于手动修改集群配置
或用于调试任务：在实践中很少使用它。

这`SETSLOT`子命令用于将插槽分配给特定节点 ID，如果
这`SETSLOT <slot> NODE`使用表单。否则，插槽可以设置在
两个特殊状态`MIGRATING`和`IMPORTING`.这两个特殊状态
用于将哈希槽从一个节点迁移到另一个节点。

*   当插槽设置为“正在迁移”时，节点将接受以下所有查询：
    都是关于这个哈希槽，但前提是有问题的密钥
    存在，否则使用`-ASK`重定向到
    作为迁移目标的节点。
*   当槽设置为“正在导入”时，节点将接受以下所有查询：
    都是关于这个哈希槽，但前提是请求是
    前面有`ASKING`命令。如果`ASKING`未发出命令
    由客户端，查询被重定向到真正的哈希槽所有者，通过
    一个`-MOVED`重定向错误，正常情况下会发生。

让我们通过哈希槽迁移的示例更清楚地说明这一点。
假设我们有两个 Redis 主节点，分别称为 A 和 B。
我们希望将哈希槽 8 从 A 移动到 B，因此我们发出如下命令：

*   我们发送 B： 集群集 8 导入 A
*   我们发送 A： 集群集 8 迁移 B

所有其他节点将继续每次将客户端指向节点“A”
他们使用属于哈希插槽8的密钥进行查询，因此会发生什么
那是：

*   有关现有密钥的所有查询均由“A”处理。
*   有关 A 中不存在的键的所有查询都由“B”处理，因为“A”会将客户端重定向到“B”。

这样，我们就不再在“A”中创建新密钥。
与此同时，`redis-cli`在重新分片期间使用
和 Redis 群集配置将迁移
从 A 到 B 的哈希槽 8。
这是使用以下命令执行的：

    CLUSTER GETKEYSINSLOT slot count

上述命令将返回`count`指定哈希槽中的键。
对于返回的密钥，`redis-cli`发送节点“A”一个`MIGRATE`命令，即
将以原子方式将指定的密钥从 A 迁移到 B（两个实例）
在迁移密钥所需的时间（通常非常短的时间）内被锁定，因此
没有争用条件）。这是如何`MIGRATE`工程：

    MIGRATE target_host target_port "" target_database id timeout KEYS key1 key2 ...

`MIGRATE`将连接到目标实例，发送序列化版本的
密钥，一旦收到OK代码，旧密钥就会来自其自己的数据集
将被删除。从外部客户端的角度来看，存在密钥
在任何给定时间在 A 或 B 中。

在 Redis 集群中，无需指定 0 以外的数据库，但
`MIGRATE`是可用于其他任务的常规命令
涉及 Redis Cluster。
`MIGRATE`经过优化，即使在移动复杂时也能尽可能快
键，如长列表，但在 Redis 集群中重新配置
如果出现大键的集群不被认为是明智的过程，如果
使用数据库的应用程序中存在延迟约束。

当迁移过程最终完成时，`SETSLOT <slot> NODE <node-id>`命令被发送到迁移中涉及的两个节点，以便
再次将插槽设置为正常状态。相同的命令通常是
发送到所有其他节点，以避免等待自然
新配置在群集中的传播。

### ASK 重定向

在上一节中，我们简要讨论了 ASK 重定向。为什么不能
我们只是使用MOVEED重定向？因为虽然移动意味着
我们认为哈希槽由不同的节点永久服务，并且
应针对指定的节点尝试下一个查询。ASK 意味着
仅将下一个查询发送到指定的节点。

这是必需的，因为有关哈希槽 8 的下一个查询可以是关于
键仍在 A 中，因此我们始终希望客户端尝试 A 和
然后 B 如果需要的话。由于这仅发生在16384中的一个哈希插槽中
可用时，群集上的性能影响是可以接受的。

我们需要强制客户端行为，以确保
客户端只会在尝试 A 后尝试节点 B，节点 B 将只尝试
接受设置为“正在导入”的槽的查询（如果客户端发送
发送查询之前执行 ASK 命令。

基本上，ASK 命令在客户端上设置一个一次性标志，该标志强制
用于提供有关导入槽的查询的节点。

从客户端的角度来看，ASK重定向的完整语义如下：

*   如果收到 ASK 重定向，则仅发送已重定向到指定节点的查询，但继续向旧节点发送后续查询。
*   使用 ASK 命令启动重定向的查询。
*   尚未更新本地客户端表以将哈希槽 8 映射到 B。

哈希槽 8 迁移完成后，A 将发送一条 MOVED 消息，并且
客户端可以将哈希槽 8 永久映射到新的终结点和端口对。
请注意，如果一个有缺陷的客户端更早地执行映射，则不是
一个问题，因为它在发出查询之前不会发送ASK命令，
因此 B 将使用 MOVED 重定向错误将客户端重定向到 A。

插槽迁移用类似的术语解释，但措辞不同
（为了文档中的冗余）在`CLUSTER SETSLOT`
命令文档。

### 客户端连接和重定向处理

为了提高效率，Redis 集群客户端维护当前插槽的映射
配置。但是，此配置不是*必填*以保持最新状态。
当联系错误的节点导致重定向时，客户端
可以相应地更新其内部插槽映射。

客户端通常需要获取插槽和映射节点的完整列表
在两种不同的情况下的地址：

*   启动时，填充初始插槽配置
*   当客户端收到`MOVED`重定向

请注意，客户端可以处理`MOVED`通过仅更新
在其表中移动插槽;然而，这通常是无效的，因为经常
将立即修改多个插槽的配置。例如，如果
副本被提升为主服务器，旧主服务器提供的所有插槽都将
重新映射）。对`MOVED`重定向方式
从头开始获取插槽到节点的完整映射。

客户端可以发出`CLUSTER SLOTS`命令以检索插槽数组
范围以及为指定范围提供服务的关联主节点和副本节点。

以下是输出的示例`CLUSTER SLOTS`:

    127.0.0.1:7000> cluster slots
    1) 1) (integer) 5461
       2) (integer) 10922
       3) 1) "127.0.0.1"
          2) (integer) 7001
       4) 1) "127.0.0.1"
          2) (integer) 7004
    2) 1) (integer) 0
       2) (integer) 5460
       3) 1) "127.0.0.1"
          2) (integer) 7000
       4) 1) "127.0.0.1"
          2) (integer) 7003
    3) 1) (integer) 10923
       2) (integer) 16383
       3) 1) "127.0.0.1"
          2) (integer) 7002
       4) 1) "127.0.0.1"
          2) (integer) 7005

返回数组中每个元素的前两个子元素是
范围的开始和结束槽。附加元素表示地址端口
对。第一个地址-端口对是为插槽提供服务的主节点，并且
其他地址端口对是服务于同一插槽的副本。副本
仅当不在错误情况下（即，未设置其 FAIL 标志时），才会列出。

上面输出中的第一个元素表示插槽从 5461 到 10922
（包括开始和结束）由127.0.0.1：7001提供服务，并且有可能
以缩放与副本联系的只读负载，地址为 127.0.0.1：7004。

`CLUSTER SLOTS`不保证返回覆盖整个范围的范围
16384 个插槽（如果群集配置错误），则客户端应初始化
槽配置映射用 NULL 对象填充目标节点，以及
如果用户尝试执行有关键的命令，则报告错误
属于未分配的插槽。

在找到插槽时向调用方返回错误之前
未分配，客户端应尝试获取插槽配置
以检查群集现在是否已正确配置。

### 多键操作

使用哈希标签，客户端可以自由使用多键操作。
例如，以下操作是有效的：

    MSET {user:1000}.name Angela {user:1000}.surname White

多键操作在重新分片时可能变得不可用
密钥所属的哈希槽正在进行中。

更具体地说，即使在重新分片期间，多键操作目标
所有存在的键，并且仍然散列到同一插槽（源或
目标节点）仍然可用。

对不存在的键执行的操作，或在重新分片期间拆分的键
在源节点和目标节点之间，将生成一个`-TRYAGAIN`错误。
客户端可以在一段时间后尝试该操作，或报告错误。

一旦指定哈希槽的迁移终止，所有
多键操作再次可用于该哈希槽。

### 使用副本节点扩展读取

通常，副本节点会将客户端重定向到
给定命令中涉及的哈希槽，但客户端可以使用副本
为了使用`READONLY`命令。

`READONLY`告诉 Redis 集群副本节点客户端可以读取
可能是陈旧数据，并且对运行写入查询不感兴趣。

当连接处于只读模式时，群集将发送重定向
仅当操作涉及未提供的密钥时，才向客户端发送
由副本的主节点执行。发生这种情况可能是因为：

1.  客户端发送了有关此副本的主节点从未提供过的哈希槽的命令。
2.  集群已重新配置（例如重新分片），副本不再能够为给定哈希槽提供命令。

发生这种情况时，客户端应更新其哈希槽映射，如中所述
前面的部分。

可以使用`READWRITE`命令。

## 容错

### 心跳和八卦消息

Redis 集群节点持续交换 ping 和 pong 数据包。这两种数据包具有相同的结构，并且都携带重要的配置信息。唯一的实际区别是消息类型字段。我们将 ping 和 pong 数据包的总和称为*心跳数据包*.

通常，节点发送 ping 数据包，这些数据包将触发接收方使用 pong 数据包进行回复。然而，这并不一定是正确的。节点可以只发送 pong 数据包，向其他节点发送有关其配置的信息，而不触发回复。例如，这很有用，以便尽快广播新配置。

通常，一个节点每秒会 ping 几个随机节点，因此无论群集中的节点数量如何，每个节点发送的 ping 数据包（和收到的 pong 数据包）的总数都是一个恒定的数量。

但是，每个节点都确保对其他每个未发送 ping 或接收 pong 的时间超过一半的节点进行 ping 操作`NODE_TIMEOUT`时间。以前`NODE_TIMEOUT`已过，节点还尝试将 TCP 链接与另一个节点重新连接，以确保节点不会因为当前 TCP 连接中存在问题而无法访问。

全局交换的消息数可以很大，如果`NODE_TIMEOUT`设置为一个小数字，节点数 （N） 非常大，因为每个节点都会每隔一半尝试 ping 一个他们没有最新信息的其他节点`NODE_TIMEOUT`时间。

例如，在节点超时设置为 60 秒的 100 节点群集中，每个节点将尝试每 30 秒发送 99 个 ping，总 ping 量为每秒 3.3 个。乘以 100 个节点，即整个群集中每秒 330 个 ping。

有一些方法可以减少消息的数量，但是没有
报告的 Redis 群集故障当前使用的带宽问题
检测，因此现在使用明显和直接的设计。请注意，即使
在上面的示例中，每秒交换的 330 个数据包是均匀的
分布在100个不同的节点中，因此每个节点接收的流量
是可以接受的。

### 检测信号数据包内容

Ping 和 pong 数据包包含所有类型的数据包（例如，请求故障转移投票的数据包）通用的标头，以及特定于 Ping 和 Pong 数据包的特殊八卦部分。

公共标头具有以下信息：

*   Node ID，一个 160 位伪随机字符串，在首次创建节点时分配，并且在 Redis 集群节点的整个生命周期内保持不变。
*   这`currentEpoch`和`configEpoch`用于挂载 Redis 集群使用的分布式算法的发送节点字段（这将在下一节中详细介绍）。如果节点是副本`configEpoch`是最后已知的`configEpoch`它的主人。
*   节点标志，指示节点是副本、主节点还是其他单位节点信息。
*   由发送节点提供服务的哈希槽的位图，或者如果节点是副本，则为其主节点提供的槽的位图。
*   发送方 TCP 基本端口，它是 Redis 用于接受客户端命令的端口。
*   群集端口，它是 Redis 用于节点到节点通信的端口。
*   从发送方的角度来看群集的状态（向下或正常）。
*   发送节点的主节点 ID（如果它是副本）。

乒乓球和乒乓球包还包含八卦部分。本节向接收方提供发送方节点对群集中其他节点的看法的视图。八卦部分仅包含有关发送者已知的节点集中的几个随机节点的信息。八卦部分中提到的节点数量与集群大小成正比。

对于在八卦部分添加的每个节点，都会报告以下字段：

*   节点 ID。
*   节点的 IP 和端口。
*   节点标志。

八卦部分允许接收节点从发送者的角度获取有关其他节点状态的信息。这对于故障检测和发现群集中的其他节点都很有用。

### 故障检测

Redis 集群故障检测用于识别大多数节点何时无法再访问主节点或副本节点，然后通过将副本提升为主节点来做出响应。当无法进行副本提升时，群集将处于错误状态，以停止接收来自客户端的查询。

如前所述，每个节点都采用与其他已知节点关联的标志列表。有两个用于故障检测的标志，称为`PFAIL`和`FAIL`.`PFAIL`方法*可能的故障*，并且是未确认的故障类型。`FAIL`表示节点出现故障，并且大多数主节点在固定时间内确认了此条件。

**PFAIL 标志：**

一个节点用`PFAIL`标记，当节点不可访问的时间超过`NODE_TIMEOUT`时间。主节点和副本节点都可以将另一个节点标记为`PFAIL`，而不考虑其类型。

Redis 集群节点的不可访问性的概念是，我们有一个**活动 ping**（我们发送的尚未收到回复的ping）等待的时间超过`NODE_TIMEOUT`.要使此机制正常工作，`NODE_TIMEOUT`与网络往返时间相比，必须很大。为了在正常操作期间增加可靠性，节点将尝试与群集中的其他节点重新连接，只要有一半`NODE_TIMEOUT`已过期，但未回复 ping。此机制可确保连接保持活动状态，因此断开的连接通常不会导致节点之间的错误故障报告。

**失败标志：**

这`PFAIL`标志本身只是每个节点具有的关于其他节点的本地信息，但仅仅触发副本升级是不够的。对于要向下考虑的节点`PFAIL`病情需要升级到`FAIL`条件。

如本文档的节点检测信号部分所述，每个节点都向其他每个节点发送八卦消息，包括几个随机已知节点的状态。每个节点最终都会收到每个其他节点的一组节点标志。这样，每个节点都有一种机制来向其他节点发出有关它们检测到的故障情况的信号。

一个`PFAIL`条件已升级到`FAIL`满足以下一组条件时的条件：

*   某个节点（我们称之为 A）将另一个节点 B 标记为`PFAIL`.
*   节点A通过八卦部分，从集群中大多数主站的角度收集有关B状态的信息。
*   大多数大师都表示`PFAIL`或`FAIL`条件`NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT`时间。（在当前实现中，有效性因子设置为 2，因此这只是`NODE_TIMEOUT`时间）。

如果上述所有条件都为真，则节点 A 将：

*   将节点标记为`FAIL`.
*   发送`FAIL`消息（与`FAIL`检测信号消息中的条件）到所有可访问的节点。

这`FAIL`消息将强制每个接收节点在`FAIL`状态，无论它是否已经标记了 中的节点`PFAIL`州。

请注意，*FAIL 标志主要是单向的*.也就是说，节点可以从`PFAIL`自`FAIL`，但`FAIL`标志只能在以下情况下清除：

*   该节点已可访问，并且是副本。在这种情况下，`FAIL`标志可以清除，因为副本未故障转移。
*   该节点已可访问，并且是不为任何插槽提供服务的主节点。在这种情况下，`FAIL`标志可以清除，因为没有插槽的主节点并不真正参与集群，并且正在等待配置以加入集群。
*   该节点已经可访问并且是主节点，但时间很长（N 乘以`NODE_TIMEOUT`） 已过期，但没有任何可检测的副本升级。在这种情况下，最好重新加入群集并继续。

值得注意的是，虽然`PFAIL`->`FAIL`过渡使用一种协议形式，使用的协议很弱：

1.  节点在一段时间内收集其他节点的视图，因此即使大多数主节点需要“同意”，实际上这只是我们在不同时间从不同节点收集的状态，我们不确定，也不要求，在给定的时刻，大多数主节点同意。但是，我们丢弃了旧的故障报告，因此大多数主站都会在一段时间内发出故障信号。
2.  当每个节点检测到`FAIL`条件将使用`FAIL`消息，没有办法确保消息将到达所有节点。例如，节点可以检测到`FAIL`条件，并且由于分区将无法访问任何其他节点。

但是，Redis 集群故障检测有一个活动性要求：最终所有节点都应就给定节点的状态达成一致。有两种情况可能源于裂脑情况。或者一些少数节点认为节点在`FAIL`状态，或少数节点认为节点不在`FAIL`州。在这两种情况下，群集最终将具有给定节点状态的单一视图：

**案例1**：如果大多数主节点已将节点标记为`FAIL`，由于故障检测和*连锁效应*它生成，每个其他节点最终都会将主节点标记为`FAIL`，因为在指定的时间范围内将报告足够的故障。

**案例 2**：当只有少数主节点将节点标记为`FAIL`，副本升级将不会发生（因为它使用更正式的算法，确保每个人最终都知道升级），并且每个节点都将清除`FAIL`状态，如`FAIL`上述状态清除规则（即 N 次后无升级`NODE_TIMEOUT`已用）。

**这`FAIL`flag 仅用作触发器来运行算法的安全部分**用于复制副本升级。从理论上讲，副本可以独立运行，并在无法访问其主节点时启动副本升级，如果大多数主副本实际上可以访问，则等待主节点拒绝提供确认。然而，增加的复杂性`PFAIL -> FAIL`状态、弱协议和`FAIL`消息强制在集群的可到达部分以最短的时间内传播状态，具有实际优势。由于这些机制，如果群集处于错误状态，通常所有节点将几乎同时停止接受写入。从使用 Redis Cluster 的应用程序的角度来看，这是一个理想的功能。此外，还避免了由由于本地问题而无法访问其主节点的副本发起的错误选举尝试（否则大多数其他主节点可以访问主节点）。

## 配置处理、传播和故障转移

### 集群当前纪元

Redis Cluster 使用类似于 Raft 算法“term”的概念。在 Redis Cluster 中，该术语称为 epoch，它用于为事件提供增量版本控制。当多个节点提供冲突的信息时，另一个节点可以了解哪个状态是最新的。

这`currentEpoch`是一个 64 位无符号数字。

在创建节点时，每个 Redis 集群节点（包括副本节点和主节点）都将`currentEpoch`到 0。

每次从另一个节点接收数据包时，如果发送方的 epoch（群集总线消息标头的一部分）大于本地节点 epoch，则`currentEpoch`更新为发送方纪元。

由于这些语义，最终所有节点都将同意最大`currentEpoch`在群集中。

当群集的状态发生更改并且节点寻求协议以执行某些操作时，将使用此信息。

目前，这仅在副本升级期间发生，如下一节所述。基本上，纪元是集群的逻辑时钟，它决定了给定的信息胜过具有较小纪元的信息。

### 配置纪元

每个大师总是宣传其`configEpoch`在 ping 和 pong 数据包中，以及一个位图，用于宣传它所服务的插槽集。

这`configEpoch`在创建新节点时，在主节点中设置为零。

一个新的`configEpoch`在副本选举期间创建。正在尝试替换的副本
失败的主节点增加其纪元并尝试从
大多数大师。授权复制副本后，新的唯一副本`configEpoch`
创建后，复制副本将使用新的`configEpoch`.

如以下各节所述`configEpoch`当不同的节点声明不同的配置（由于网络分区和节点故障而可能发生的情况）时，有助于解决冲突。

副本节点还通告`configEpoch`在 ping 和 pong 数据包中字段，但在副本的情况下，该字段表示`configEpoch`截至上次交换数据包时的主服务器。这允许其他实例检测副本何时具有需要更新的旧配置（主节点不会向具有旧配置的副本授予投票）。

每次`configEpoch`对于某些已知节点，它由接收此信息的所有节点永久存储在 nodes.conf 文件中。同样的事情也发生在`currentEpoch`价值。这两个变量保证被保存并且`fsync-ed`在节点继续其操作之前进行更新时添加到磁盘。

这`configEpoch`在故障转移期间使用简单算法生成的值
保证是新的、增量的和唯一的。

### 复制品选择和升级

副本选举和升级由副本节点处理，在主节点的帮助下，主节点投票支持副本进行升级。
当主节点位于`FAIL`状态从其至少一个副本的角度来看，该副本具有成为主服务器的先决条件。

为了使复制品将自己提升为主控者，它需要开始选举并赢得选举。如果主服务器位于`FAIL`然而，只有一个复制品才能赢得选举，并提升自己成为主人。

当满足以下条件时，副本将启动选举：

*   复制副本的主节点位于`FAIL`州。
*   主服务器提供非零数量的插槽。
*   副本复制链路与主服务器的断开连接的时间不超过给定时间，以确保提升的副本的数据是相当新鲜的。此时间是用户可配置的。

为了当选，复制副本的第一步是增加其`currentEpoch`计数器，并从主实例请求投票。

复制副本通过广播`FAILOVER_AUTH_REQUEST`数据包到集群的每个主节点。然后，它等待的最大时间是`NODE_TIMEOUT`以便回复到达（但始终至少 2 秒）。

一旦主站对给定的副本进行了投票，并积极回复`FAILOVER_AUTH_ACK`，则它不能再投票支持同一主节点的另一个副本，有效期为`NODE_TIMEOUT * 2`.在此期间，它将无法回复同一主服务器的其他授权请求。这不是保证安全性所必需的，但对于防止多个副本被选中（即使具有不同的副本）很有用`configEpoch`），这通常是不想要的。

复制副本将丢弃任何`AUTH_ACK`回复的纪元小于`currentEpoch`在发送投票请求时。这可确保它不会计算用于上次选举的选票。

一旦副本从大多数主节点接收到 ACK，它就会赢得选举。
否则，如果在两次的时间内未达到多数`NODE_TIMEOUT`（但始终至少 2 秒），选举将中止，新的选举将在以下时间后再次尝试`NODE_TIMEOUT * 4`（并且始终至少 4 秒）。

### 副本排名

一旦主人在`FAIL`状态，副本在尝试当选之前等待一小段时间。该延迟的计算方法如下：

    DELAY = 500 milliseconds + random delay between 0 and 500 milliseconds +
            REPLICA_RANK * 1000 milliseconds.

固定延迟确保我们等待`FAIL`状态在群集中传播，否则副本可能会尝试在主节点仍不知道`FAIL`状态，拒绝给予他们的投票。

随机延迟用于取消同步副本，因此它们不太可能同时启动选举。

这`REPLICA_RANK`是此副本相对于它从主服务器处理的复制数据量的等级。
当主服务器出现故障时，副本交换消息，以便建立（尽力而为）等级：
具有最多更新复制偏移量的副本位于 0 级，第二个更新次数最多的副本位于 1 级，依此类推。
通过这种方式，更新的副本尝试在其他人之前当选。

排名顺序没有严格执行;如果更高等级的副本无法
当选后，其他人将很快尝试。

一旦副本赢得选举，它就会获得一个新的唯一增量`configEpoch`它高于任何其他现有主站。它开始将自己宣传为乒乓球和乒乓球包中的主服务器，为服务插槽集提供`configEpoch`这将战胜过去的。

为了加快其他节点的重新配置，将 pong 数据包广播到群集的所有节点。当前无法访问的节点最终将在从另一个节点接收 ping 或 pong 数据包时重新配置，或者将收到`UPDATE`来自另一个节点的数据包（如果它通过检测信号数据包发布的信息被检测到已过期）。

其他节点将检测到有一个新的主节点服务于旧主服务器所服务的相同插槽，但具有更大的`configEpoch`，并将升级其配置。旧主服务器（或故障转移的主服务器，如果它重新加入群集）的副本不仅会升级配置，还会重新配置以从新主服务器进行复制。以下各节将介绍如何配置重新加入群集的节点。

### 大师回复复制人投票请求

在上一节中，我们讨论了副本如何尝试当选。本节从请求为给定副本投票的主节点的角度解释所发生的情况。

硕士以以下形式收到投票请求`FAILOVER_AUTH_REQUEST`来自副本的请求。

要获得投票权，需要满足以下条件：

1.  一个主子只为一个给定的纪元投票一次，并拒绝为较老的纪元投票：每个主都有一个lastVoteEpoch字段，并且只要`currentEpoch`中的身份验证请求数据包不大于最后一个投票。当主站对投票请求做出肯定的回复时，lastVoteEpoch 会相应地更新，并安全地存储在磁盘上。
2.  仅当副本的主节点被标记为`FAIL`.
3.  使用`currentEpoch`小于主`currentEpoch`将被忽略。因此，主回复将始终具有相同的`currentEpoch`作为身份验证请求。如果同一副本再次要求投票，则递增`currentEpoch`，可以保证来自主站的旧延迟回复不能被接受为新的投票。

因未使用规则编号 3 而导致的问题示例：

主人`currentEpoch`是5，lastVoteEpoch是1（这可能发生在几次失败的选举之后）

*   复制品`currentEpoch`为 3。
*   复制副本尝试使用 epoch 4 （3+1） 进行选择，主版本回复为 ok with`currentEpoch`5、但是回复被延迟了。
*   复制副本将尝试在稍后的时间再次被选举，具有epoch 5（4 + 1），延迟的回复到达副本`currentEpoch`5、并被接受为有效。

4.  大师之前不会投票支持同一大师的副本`NODE_TIMEOUT * 2`如果该主节点的副本已被投票支持，则已过期。这不是严格要求的，因为两个副本不可能在同一时期赢得选举。但是，实际上，它确保在选择副本时，它有足够的时间通知其他副本，并避免另一个副本将赢得新的选举，从而执行不必要的第二次故障转移。
5.  Masters 不会以任何方式选择最佳副本。如果复制副本的主节点位于`FAIL`州和主人在当前任期内没有投票，给予赞成票。最好的副本是最有可能在其他副本之前开始选举并赢得选举的复制副本，因为它通常能够更早地开始投票过程*更高的等级*如上一节所述。
6.  当主节点拒绝为给定的副本投票时，没有否定响应，该请求将被忽略。
7.  母版不投票支持副本发送`configEpoch`小于任何`configEpoch`在复制副本声明的插槽的主表中。请记住，副本将`configEpoch`的母版，以及其主服务器所服务的插槽的位图。这意味着请求投票的副本必须具有要故障转移的插槽的配置，该配置较新或等于授予投票的主节点的配置。

### 分区期间配置 epoch 有用性的实际示例

本节说明如何使用 epoch 概念使副本升级过程对分区更具抵抗力。

*   无法再无限期地访问主节点。主站有三个副本 A、B、C。
*   副本 A 赢得选举并晋升为主副本。
*   网络分区使 A 对群集的大多数不可用。
*   副本 B 赢得选举并提升为主服务器。
*   分区使 B 对群集的大多数部分不可用。
*   上一个分区已修复，A 再次可用。

此时，B 已关闭，A 再次可用，并具有 master 角色（实际上`UPDATE`消息会立即重新配置它，但在这里我们假设所有`UPDATE`消息已丢失）。同时，副本 C 将尝试当选，以便故障转移 B。这是发生的事情：

1.  C将试图当选并取得成功，因为对于大多数大师来说，它的主人实际上是下台的。它将获得新的增量`configEpoch`.
2.  A 将无法声称自己是其哈希槽的主节点，因为与 A 发布的哈希槽相比，其他节点已经具有与更高配置纪元（B 的纪元）关联的相同哈希槽。
3.  因此，所有节点都将升级其表以将哈希槽分配给 C，并且群集将继续其操作。

正如您将在下一节中看到的，一个过时的节点重新加入集群
通常会尽快收到有关配置更改的通知
因为一旦它ping任何其他节点，接收者就会检测到它
具有过时的信息，并将发送`UPDATE`消息。

### 哈希槽配置传播

Redis 集群的一个重要部分是用于传播有关哪个集群节点正在为一组给定哈希槽提供服务的信息的机制。这对于新群集的启动以及在提升副本以为其故障主服务器的插槽提供服务后升级配置的能力都至关重要。

相同的机制允许节点无限期地分区
是时候以合理的方式重新加入集群了。

传播哈希槽配置的方式有两种：

1.  检测信号消息。ping 或 pong 数据包的发送方始终添加有关它（或其主节点，如果它是副本）所服务的哈希槽集的信息。
2.  `UPDATE`消息。因为在每个检测信号数据包中都有关于发送方的信息`configEpoch`和一组哈希槽服务，如果一个心跳数据包的接收者发现发送方信息是陈旧的，它将发送一个包含新信息的数据包，迫使陈旧的节点更新其信息。

检测信号的接收器或`UPDATE`消息在
以更新其表将哈希槽映射到节点。创建新的 Redis 集群节点时，其本地哈希槽表只需初始化为`NULL`条目，以便每个哈希槽不绑定或链接到任何节点。这类似于以下内容：

    0 -> NULL
    1 -> NULL
    2 -> NULL
    ...
    16383 -> NULL

为了更新节点的哈希槽表，节点后跟的第一条规则如下：

**规 则 1**：如果哈希槽未分配（设置为`NULL`），并且已知节点声明它，我将修改我的哈希槽表并将已声明的哈希槽关联到它。

因此，如果我们从节点 A 收到一个检测信号，声称为配置 epoch 值为 3 的哈希槽 1 和 2 提供服务，则该表将修改为：

    0 -> NULL
    1 -> A [3]
    2 -> A [3]
    ...
    16383 -> NULL

创建新群集时，系统管理员需要手动分配（使用`CLUSTER ADDSLOTS`命令，通过 redis-cli 命令行工具，或通过任何其他方式）每个主节点仅向节点本身提供的插槽，并且信息将在整个集群中快速传播。

然而，这个规则是不够的。我们知道哈希槽映射可以改变
在两个事件期间：

1.  副本在故障转移期间替换其主节点。
2.  插槽从节点重新分片到其他节点。

现在，让我们重点关注故障转移。当副本故障转移其主节点时，它可获得
一个配置纪元，保证大于其一个
主（并且通常大于任何其他配置纪元
之前生成）。例如，节点 B 是 A 的副本，可以进行故障转移
配置纪元为 4 的 A。它将开始发送检测信号数据包
（第一次在集群范围内进行群发广播）并且由于以下原因
第二条规则，接收方将更新其哈希槽表：

**第2条**：如果已分配哈希槽，并且已知节点正在使用`configEpoch`大于`configEpoch`对于当前与该槽关联的主节点，我将哈希槽重新绑定到新节点。

因此，在从 B 接收到声称为配置 epoch 为 4 的哈希槽 1 和 2 的消息后，接收方将按以下方式更新其表：

    0 -> NULL
    1 -> B [4]
    2 -> B [4]
    ...
    16383 -> NULL

活动属性：由于第二条规则，最终群集中的所有节点都将同意插槽的所有者是具有最大权限的节点`configEpoch`在节点中宣传它。

Redis 集群中的这种机制称为**上次故障转移获胜**.

在重新分片期间也会发生同样的情况。当节点导入哈希槽完成时
导入操作，其配置 epoch 递增以确保
更改将在整个群集中传播。

### 更新消息，仔细观察

考虑到上一节，更容易看到如何更新消息
工作。节点 A 可能会在一段时间后重新加入群集。它将发送心跳
它声称它为具有配置 epoch 的哈希槽 1 和 2 提供服务的数据包
的 3.所有具有更新信息的接收器将改为看到
相同的哈希槽与具有更高配置的节点 B 相关联
时代。因此，他们将发送一个`UPDATE`给 A 的消息与新的
插槽的配置。A 将更新其配置，因为
**第2条**以上。

### 节点如何重新加入群集

当节点重新加入群集时，将使用相同的基本机制。
继续上面的示例，节点 A 将收到通知
哈希槽 1 和 2 现在由 B 提供服务。假设这两个插槽是
A 提供的唯一哈希槽，A 将服务的哈希槽计数
降至 0！所以A遗嘱**重新配置为新主服务器的副本**.

实际遵循的规则比这更复杂。一般来说，它可能
碰巧A在很多时间后重新加入，在此期间可能会发生
最初由 A 提供服务的哈希槽由多个节点提供服务，例如
哈希槽 1 可以由 B 提供服务，哈希槽 2 可以由 C 提供服务。

所以实际*Redis 集群节点角色切换规则*是：**主节点将更改其配置以复制（成为）窃取其最后一个哈希插槽的节点的副本**.

在重新配置期间，最终提供的哈希槽数将降至零，并且节点将相应地重新配置。请注意，在基本情况下，这只是意味着旧的主服务器将是故障转移后替换它的副本的副本。然而，在一般形式上，该规则涵盖了所有可能的情况。

副本执行完全相同的操作：它们重新配置以复制节点
偷走了其前主人的最后一个哈希槽。

### 副本迁移

Redis Cluster 实现了一个概念，称为*副本迁移*为了
提高系统的可用性。这个想法是，在集群中
主副本设置（如果副本和主副本之间的映射是固定的）
如果单个独立故障的多个独立故障，则可用性会随着时间的推移而受到限制
节点发生。

例如，在每个主节点都有一个副本的群集中，群集
只要主服务器或复制副本发生故障，就可以继续操作，但不能
如果两者同时失败。但是，有一类故障是
由硬件或软件问题引起的单个节点的独立故障
可以随着时间的推移而积累。例如：

*   主 A 具有单个副本 A1。
*   主 A 失败。A1 被提升为新的主节点。
*   三小时后，A1以独立的方式失败（与A的失败无关）。没有其他副本可用于升级，因为节点 A 仍处于关闭状态。群集无法继续正常操作。

如果主服务器和副本之间的映射是固定的，则制作群集的唯一方法
但是，对上述情况的抵抗力更强的是将副本添加到每个主服务器
这是昂贵的，因为它需要更多的Redis实例来执行，更多
记忆，等等。

另一种方法是在集群中创建不对称，并让集群
布局会随时间自动更改。例如，群集可能有三个
大师A，B，C。A 和 B 各有一个副本，A1 和 B1。然而，大师
C 是不同的，有两个副本：C1 和 C2。

副本迁移是复制副本自动重新配置的过程
为了*迁移*到不再覆盖的主控（不工作）
副本）。通过副本迁移，上面提到的方案变成了
以后：

*   主 A 失败。A1 已升级。
*   C2 作为 A1 的副本迁移，否则该副本不受任何副本的支持。
*   三小时后，A1也失败了。
*   C2 被提升为新的主节点以取代 A1。
*   群集可以继续操作。

### 副本迁移算法

迁移算法不使用任何形式的协议，因为副本
Redis 集群中的布局不是需要的集群配置的一部分
与配置 epoch 保持一致和/或版本控制。相反，它使用
算法，以避免在主服务器未备份时大规模迁移副本。
该算法保证最终（一旦群集配置
stable） 每个主站都将由至少一个副本提供支持。

这就是算法的工作原理。首先，我们需要定义什么是
*良好的复制品*在此上下文中：一个好的复制品是一个不在`FAIL`州
从给定节点的角度来看。

算法的执行在每个检测到以下情况的副本中触发
至少有一个主站没有良好的副本。然而，在所有
副本检测到这种情况时，只有子集应执行操作。此子集是
实际上通常是单个副本，除非不同的副本在给定的时刻
其他节点的故障状态视图略有不同。

这*代理复制副本*是主服务器中具有最大数量的副本
的附加副本，该副本未处于 FAIL 状态且具有最小的节点 ID。

例如，如果有 10 个主站，每个主站有 1 个副本，而 2 个主站具有
每个副本 5 个副本，将尝试迁移的副本位于 2 个主副本中
具有 5 个副本 - 具有最低节点 ID 的副本。鉴于没有协议
使用时，可能当群集配置不稳定时，
当多个副本认为自己是
具有较低节点 ID 的非故障副本（不太可能发生这种情况
在实践中）。如果发生这种情况，结果是多个副本迁移到
同一个主人，这是无害的。如果比赛以一种会离开的方式发生
没有副本的让出主服务器，只要群集再次稳定
该算法将再次重新执行，并将副本迁移回
原始母版。

最终，每个主站都将由至少一个副本提供支持。然而
正常行为是单个副本从主节点迁移
将多个副本添加到孤立的主节点。

该算法由用户可配置的参数控制，称为
`cluster-migration-barrier`：一个主站的良好副本数
必须先保留，然后才能迁移副本。例如，如果
参数设置为 2，仅当副本的主服务器仍然存在时，副本才能尝试迁移
具有两个工作副本。

### 配置Epoch 冲突解决算法

当新`configEpoch`值是在复制副本升级期间通过复制副本升级创建的
故障转移，它们保证是唯一的。

但是，有两个不同的事件，其中新的配置Epoch值为
以不安全的方式创建，只是增加本地`currentEpoch`之
本地节点，并希望同时没有冲突。
这两个事件都是系统管理员触发的：

1.  `CLUSTER FAILOVER`命令`TAKEOVER`选项能够手动将副本节点提升为主节点*没有大多数主站可用*.例如，这在多数据中心设置中很有用。
2.  出于性能原因，迁移用于群集重新平衡的插槽还会在本地节点内生成新的配置纪元，而无需达成一致。

具体而言，在手动重新分片期间，当哈希槽从
一个节点A到一个节点B，重新分片程序会强制B升级
它的配置到一个纪元，这是在集群中发现的最大的时代，
加 1（除非节点已经是配置最出色的节点）
epoch），而无需其他节点的同意。
通常，现实世界的重新分片涉及移动数百个哈希槽
（特别是在小集群中）。需要协议才能生成新的
重新分片期间的配置纪元，对于移动的每个哈希槽，是
低 效。此外，它需要在每个群集节点中都有一个 fsync
每次为了存储新配置。因为它的方式
相反，当第一个哈希槽被移动时，我们只需要一个新的配置纪元，
使其在生产环境中更加高效。

但是，由于上述两种情况，有可能（尽管不太可能）结束
具有相同配置纪元的多个节点。重新分片操作
由系统管理员执行，并同时发生故障转移
时间（加上很多坏运气）可能会导致`currentEpoch`冲突在以下情况下
它们的传播速度不够快。

此外，软件错误和文件系统损坏也可能导致
到具有相同配置纪元的多个节点。

当提供不同哈希槽的主节点具有相同的哈希插槽时`configEpoch`那里
都没有问题。更重要的是，故障转移主服务器的副本具有
唯一配置纪元。

也就是说，手动干预或重新分片可能会更改集群
以不同的方式进行配置。Redis Cluster 主要活动属性
要求插槽配置始终融合，因此在任何情况下
我们真的希望所有的主节点都有一个不同的`configEpoch`.

为了执行这一点，**冲突解决算法**用于
事件，即两个节点最终具有相同的`configEpoch`.

*   如果一个主节点检测到另一个主节点正在用
    一样`configEpoch`.
*   如果该节点的字典上与声称相同的另一个节点相比，其节点 ID 在字典上更小`configEpoch`.
*   然后它增加其`currentEpoch`由 1，并将其用作新的`configEpoch`.

如果有任何一组节点具有相同的`configEpoch`，除了具有最大节点ID的节点之外，所有节点都将向前移动，从而保证最终，无论发生什么情况，每个节点都将选择一个唯一的configEpoch。

此机制还保证在创建新群集后，所有
节点以不同的节点开头`configEpoch`（即使这实际上不是
使用）自`redis-cli`确保使用`CLUSTER SET-CONFIG-EPOCH`启动时。
但是，如果由于某种原因节点配置错误，它将更新
其配置自动更改为不同的配置纪元。

### 节点重置

节点可以进行软件重置（无需重新启动），以便重复使用
在不同的角色或不同的集群中。这在正常情况下很有用
操作，在测试中，以及在给定节点可以
重新预配以加入一组不同的节点以放大或创建新的节点
簇。

在 Redis 群集中，节点使用`CLUSTER RESET`命令。这
命令以两种变体提供：

*   `CLUSTER RESET SOFT`
*   `CLUSTER RESET HARD`

必须将命令直接发送到节点才能重置。如果没有重置类型
提供，则执行软复位。

以下是重置执行的操作列表：

1.  软复位和硬复位：如果节点是副本，则将其转换为主节点，并丢弃其数据集。如果节点是主节点并包含密钥，则重置操作将中止。
2.  软重置和硬重置：释放所有插槽，并重置手动故障转移状态。
3.  软复位和硬复位：节点表中的所有其他节点都将被删除，因此该节点不再知道任何其他节点。
4.  仅硬重置：`currentEpoch`,`configEpoch`和`lastVoteEpoch`设置为 0。
5.  仅硬重置：节点 ID 更改为新的随机 ID。

具有非空数据集的主节点无法重置（因为通常您希望将数据重新分片到其他节点）。但是，在特殊条件下（例如，当一个集群被完全销毁以创建新的集群时），`FLUSHALL`必须在继续重置之前执行。

### 从群集中删除节点

实际上，可以通过以下方式从现有群集中删除节点：
将其所有数据重新分片到其他节点（如果它是主节点）和
将其关闭。但是，其他节点仍将记住其节点
ID 和地址，并将尝试与其连接。

因此，当一个节点被删除时，我们也想删除它的条目。
从所有其他节点表中。这是通过使用
`CLUSTER FORGET <node-id>`命令。

该命令执行两项操作：

1.  它从节点表中删除具有指定节点 ID 的节点。
2.  它设置了一个 60 秒的禁令，可防止重新添加具有相同节点 ID 的节点。

第二个操作是必需的，因为 Redis Cluster 使用八卦来自动发现节点，因此从节点 A 中删除节点 X 可能会导致节点 B 再次向 A 八卦节点 X。由于 60 秒的禁令，Redis 集群管理工具有 60 秒的时间从所有节点中删除节点，从而防止由于自动发现而重新添加节点。

更多信息请见`CLUSTER FORGET`文档。

## 发布/订阅

在 Redis 集群中，客户端可以订阅每个节点，还可以
发布到所有其他节点。群集将确保已发布
根据需要转发邮件。

客户端可以将 SUBSCRIBE 发送到任何节点，也可以将 PUBLISH 发送到任何节点。
它只是将每个已发布的消息广播到所有其他节点。

Redis 7.0 及更高版本具有分片 pub/sub 功能，其中分片通道通过用于将密钥分配给槽的相同算法分配给槽。
分片消息必须发送到拥有分片通道哈希到的插槽的节点。
集群确保将已发布的分片消息转发到分片中的所有节点，以便客户端可以通过连接到负责插槽的主节点或其任何副本来订阅分片通道。

## 附录

### 附录 A：ANSI C 中的 CRC16 参考实现

    /*
     * Copyright 2001-2010 Georges Menie (www.menie.org)
     * Copyright 2010 Salvatore Sanfilippo (adapted to Redis coding style)
     * All rights reserved.
     * Redistribution and use in source and binary forms, with or without
     * modification, are permitted provided that the following conditions are met:
     *
     *     * Redistributions of source code must retain the above copyright
     *       notice, this list of conditions and the following disclaimer.
     *     * Redistributions in binary form must reproduce the above copyright
     *       notice, this list of conditions and the following disclaimer in the
     *       documentation and/or other materials provided with the distribution.
     *     * Neither the name of the University of California, Berkeley nor the
     *       names of its contributors may be used to endorse or promote products
     *       derived from this software without specific prior written permission.
     *
     * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND ANY
     * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
     * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
     * DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY
     * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
     * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
     * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
     * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
     * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
     * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
     */

    /* CRC16 implementation according to CCITT standards.
     *
     * Note by @antirez: this is actually the XMODEM CRC 16 algorithm, using the
     * following parameters:
     *
     * Name                       : "XMODEM", also known as "ZMODEM", "CRC-16/ACORN"
     * Width                      : 16 bit
     * Poly                       : 1021 (That is actually x^16 + x^12 + x^5 + 1)
     * Initialization             : 0000
     * Reflect Input byte         : False
     * Reflect Output CRC         : False
     * Xor constant to output CRC : 0000
     * Output for "123456789"     : 31C3
     */

    static const uint16_t crc16tab[256]= {
        0x0000,0x1021,0x2042,0x3063,0x4084,0x50a5,0x60c6,0x70e7,
        0x8108,0x9129,0xa14a,0xb16b,0xc18c,0xd1ad,0xe1ce,0xf1ef,
        0x1231,0x0210,0x3273,0x2252,0x52b5,0x4294,0x72f7,0x62d6,
        0x9339,0x8318,0xb37b,0xa35a,0xd3bd,0xc39c,0xf3ff,0xe3de,
        0x2462,0x3443,0x0420,0x1401,0x64e6,0x74c7,0x44a4,0x5485,
        0xa56a,0xb54b,0x8528,0x9509,0xe5ee,0xf5cf,0xc5ac,0xd58d,
        0x3653,0x2672,0x1611,0x0630,0x76d7,0x66f6,0x5695,0x46b4,
        0xb75b,0xa77a,0x9719,0x8738,0xf7df,0xe7fe,0xd79d,0xc7bc,
        0x48c4,0x58e5,0x6886,0x78a7,0x0840,0x1861,0x2802,0x3823,
        0xc9cc,0xd9ed,0xe98e,0xf9af,0x8948,0x9969,0xa90a,0xb92b,
        0x5af5,0x4ad4,0x7ab7,0x6a96,0x1a71,0x0a50,0x3a33,0x2a12,
        0xdbfd,0xcbdc,0xfbbf,0xeb9e,0x9b79,0x8b58,0xbb3b,0xab1a,
        0x6ca6,0x7c87,0x4ce4,0x5cc5,0x2c22,0x3c03,0x0c60,0x1c41,
        0xedae,0xfd8f,0xcdec,0xddcd,0xad2a,0xbd0b,0x8d68,0x9d49,
        0x7e97,0x6eb6,0x5ed5,0x4ef4,0x3e13,0x2e32,0x1e51,0x0e70,
        0xff9f,0xefbe,0xdfdd,0xcffc,0xbf1b,0xaf3a,0x9f59,0x8f78,
        0x9188,0x81a9,0xb1ca,0xa1eb,0xd10c,0xc12d,0xf14e,0xe16f,
        0x1080,0x00a1,0x30c2,0x20e3,0x5004,0x4025,0x7046,0x6067,
        0x83b9,0x9398,0xa3fb,0xb3da,0xc33d,0xd31c,0xe37f,0xf35e,
        0x02b1,0x1290,0x22f3,0x32d2,0x4235,0x5214,0x6277,0x7256,
        0xb5ea,0xa5cb,0x95a8,0x8589,0xf56e,0xe54f,0xd52c,0xc50d,
        0x34e2,0x24c3,0x14a0,0x0481,0x7466,0x6447,0x5424,0x4405,
        0xa7db,0xb7fa,0x8799,0x97b8,0xe75f,0xf77e,0xc71d,0xd73c,
        0x26d3,0x36f2,0x0691,0x16b0,0x6657,0x7676,0x4615,0x5634,
        0xd94c,0xc96d,0xf90e,0xe92f,0x99c8,0x89e9,0xb98a,0xa9ab,
        0x5844,0x4865,0x7806,0x6827,0x18c0,0x08e1,0x3882,0x28a3,
        0xcb7d,0xdb5c,0xeb3f,0xfb1e,0x8bf9,0x9bd8,0xabbb,0xbb9a,
        0x4a75,0x5a54,0x6a37,0x7a16,0x0af1,0x1ad0,0x2ab3,0x3a92,
        0xfd2e,0xed0f,0xdd6c,0xcd4d,0xbdaa,0xad8b,0x9de8,0x8dc9,
        0x7c26,0x6c07,0x5c64,0x4c45,0x3ca2,0x2c83,0x1ce0,0x0cc1,
        0xef1f,0xff3e,0xcf5d,0xdf7c,0xaf9b,0xbfba,0x8fd9,0x9ff8,
        0x6e17,0x7e36,0x4e55,0x5e74,0x2e93,0x3eb2,0x0ed1,0x1ef0
    };

    uint16_t crc16(const char *buf, int len) {
        int counter;
        uint16_t crc = 0;
        for (counter = 0; counter < len; counter++)
                crc = (crc<<8) ^ crc16tab[((crc>>8) ^ *buf++)&0x00FF];
        return crc;
    }

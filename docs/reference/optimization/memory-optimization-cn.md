***

标题： 内存优化
链接标题： 内存优化
描述： 在 Redis 中优化内存使用的策略
体重： 1
别名：

*   /topics/memory-optimization

***

## 小型聚合数据类型的特殊编码

从 Redis 2.2 开始，许多数据类型都经过优化，可以在达到一定大小的情况下使用更少的空间。
哈希、列表、仅由整数组成的集和排序集（当小于给定数量的元素且最大元素大小）以非常内存有效的方式进行编码，该方式使用*内存最多减少 10 倍*（平均节省的内存减少了5倍）。

从用户和API的角度来看，这是完全透明的。
由于这是CPU/内存的权衡，因此可以调整最大值
特殊编码类型的元素数和最大元素大小
使用以下 redis.conf 指令。

    hash-max-ziplist-entries 512
    hash-max-ziplist-value 64
    zset-max-ziplist-entries 128
    zset-max-ziplist-value 64
    set-max-intset-entries 512

如果特殊编码的值溢出配置的最大大小，
Redis 会自动将其转换为正常编码。
对于小值，此操作非常快，
但是，如果您更改设置以使用特殊编码的值
对于更大的聚合类型，建议运行一些
基准测试和测试，以检查转换时间。

## 使用 32 位实例

使用32位目标编译的Redis每个键使用的内存要少得多，因为指针很小，
但这样的实例将被限制为4 GB的最大内存使用量。
要将 Redis 编译为 32 位二进制文件，请使用*使32位*.
RDB 和 AOF 文件在 32 位和 64 位实例之间兼容
（当然，在小端和大端之间），因此您可以从32位切换到64位，或者相反，没有问题。

## 位和字节级操作

Redis 2.2 引入了新的位和字节级操作：`GETRANGE`,`SETRANGE`,`GETBIT`和`SETBIT`.
使用这些命令，您可以将 Redis 字符串类型视为随机访问数组。
例如，如果您有一个应用程序，其中用户由唯一的渐进整数标识，
您可以使用位图在邮件列表中保存有关用户订阅的信息，
设置已订阅的位并将其清除为取消订阅，反之亦然。
对于 1 亿用户，这些数据在 Redis 实例中仅占用 12 MB 的 RAM。
您可以使用以下命令执行相同的操作`GETRANGE`和`SETRANGE`以便为每个用户存储一个字节的信息。
这只是一个例子，但实际上可以使用这些新基元在很小的空间内对许多问题进行建模。

## 尽可能使用哈希

小哈希值在非常小的空间内进行编码，因此应尽可能尝试使用哈希值来表示数据。
例如，如果您在 Web 应用程序中具有表示用户的对象，
而不是对姓名，姓氏，电子邮件，密码使用不同的键，而是使用带有所有必填字段的单个哈希。

如果您想了解有关此内容的更多信息，请阅读下一节。

## 使用哈希在 Redis 之上抽象出一个非常内存高效的普通键值存储

我知道本节的标题有点吓人，但我将详细解释这是关于什么的。

基本上，可以使用 Redis 对普通键值存储进行建模
其中值可以只是字符串，而不仅仅是更高的内存效率
比Redis普通键，但也比memcached的内存效率高得多。

让我们从一些事实开始：几个键比单个键使用更多的内存
包含一个包含几个字段的哈希。这怎么可能？我们使用了一个技巧。
从理论上讲，为了保证我们在恒定时间内执行查找
（在大O表示法中也称为O（1））需要使用数据结构
在一般情况下具有恒定的时间复杂度，例如哈希表。

但很多时候，哈希只包含几个字段。当哈希值很小时，我们可以
而是将它们编码为O（N）数据结构，如线性
具有长度前缀键值对的数组。因为我们只在 N
很小，HGET 和 HSET 命令的摊销时间仍然是 O（1）：
只要元素数量增加，hash 就会被转换为真正的哈希表
它包含增长过大（您可以在 redis.conf 中配置限制）。

从时间复杂度的角度来看，这不仅效果很好，而且
也从常数时间的角度来看，由于线性阵列键
值对恰好与CPU缓存配合得很好（它有更好的
缓存位置而不是哈希表）。

但是，由于哈希字段和值（始终）表示为完整
精选 Redis 对象，哈希字段不能有关联的生存时间
（expire） 像一个真正的密钥，并且只能包含一个字符串。但我们没关系
这，这是哈希数据类型API的意图
设计（我们信任简单性多于功能，因此嵌套数据结构
不允许，因为不允许单个字段过期）。

因此，哈希值是内存高效的。这在使用哈希值时很有用
表示对象或对存在组
相关字段。但是，如果我们有一个普通的键值业务呢？

想象一下，我们想要使用Redis作为许多小对象的缓存，这些小对象可以是
JSON 编码的对象、小 HTML 片段、简单键 -> 布尔值
等等。基本上任何东西都是一个字符串 ->字符串映射，带有小键
和值。

现在，让我们假设我们要缓存的对象已编号，例如：

*   对象：102393
*   对象：1234
*   对象：5

这是我们能做的。每次我们执行
SET操作来设置一个新值，我们实际上将密钥分成两部分，
一部分用作键，另一部分用作哈希的字段名称。例如
名为“object：1234”的对象实际上被拆分为：

*   a 键命名对象：12
*   a 名为 34 的字段

因此，我们使用所有字符，但最后两个字符作为密钥，最后一个字符
哈希字段名称的两个字符。为了设置我们的密钥，我们使用以下内容
命令：

    HSET object:12 34 somevalue

如您所见，每个哈希值都将包含 100 个字段，即
是 CPU 和保存内存之间的最佳折衷方案。

还有另一件重要的事情需要注意，有了这个架构
每个哈希将有更多或
少于 100 个字段，无论我们缓存的对象数量如何。这是从
我们的对象将始终以数字结尾，而不是随机字符串。在一些
最终数字可以被视为隐式预分片的一种形式。

那么小数字呢？喜欢对象：2？我们处理这种情况时只需
“object：”作为键名，整数作为哈希字段名称。
因此，object：2 和 object：10 都将在键“object：”内结束，但只有一个
字段名称为“2”，其中一个为“10”。

我们以这种方式节省多少内存？

我使用以下Ruby程序来测试它是如何工作的：

```ruby
require 'rubygems'
require 'redis'

USE_OPTIMIZATION = true

def hash_get_key_field(key)
  s = key.split(':')
  if s[1].length > 2
    { key: s[0] + ':' + s[1][0..-3], field: s[1][-2..-1] }
  else
    { key: s[0] + ':', field: s[1] }
  end
end

def hash_set(r, key, value)
  kf = hash_get_key_field(key)
  r.hset(kf[:key], kf[:field], value)
end

def hash_get(r, key, value)
  kf = hash_get_key_field(key)
  r.hget(kf[:key], kf[:field], value)
end

r = Redis.new
(0..100_000).each do |id|
  key = "object:#{id}"
  if USE_OPTIMIZATION
    hash_set(r, key, 'val')
  else
    r.set(key, 'val')
  end
end
```

这是针对 Redis 2.2 的 64 位实例的结果：

*   USE_OPTIMIZATION设置为 true：1.7 MB 的已用内存
*   USE_OPTIMIZATION设置为 false;11 MB 已用内存

这是一个数量级，我认为这或多或少使Redis成为最多的
内存高效的普通键值存储在那里。

*警告*：要使此功能正常工作，请确保在您的 redis.conf 中
像这样：

    hash-max-zipmap-entries 256

还要记住根据最大大小设置以下字段
的键和值：

    hash-max-zipmap-value 1024

每当哈希超过指定的元素数或元素大小时
它将被转换为真正的哈希表，并且内存节省将丢失。

您可能会问，为什么不在正常的密钥空间中隐式执行此操作，以便
我不必在乎？原因有二：一是我们倾向于制造
权衡是明确的，这是许多事情之间的明显权衡：CPU，
内存，最大元素大小。二是顶层键空间必须
支持很多有趣的东西，如过期，LRU数据等
因此，以一般的方式这样做是不切实际的。

但Redis的方式是，用户必须了解事物的工作原理，以便
他能够选择最好的折衷方案，并了解系统将如何
行为准确。

## 内存分配

为了存储用户密钥，Redis 分配的内存最多与`maxmemory`
设置启用（但是可能有少量的额外分配）。

确切的值可以在配置文件中设置，也可以稍后通过以下方式设置
`CONFIG SET`（请参见[使用内存作为 LRU 缓存以获取更多信息](https://redis.io/topics/lru-cache)).
关于 Redis 如何管理内存，有几点需要注意：

*   删除密钥时，Redis 不会始终将内存释放（返回）到操作系统。
    这并不是 Redis 的特别之处，但这是大多数 malloc（） 实现的工作方式。
    例如，如果您用 5GB 的数据填充实例，然后
    删除相当于 2GB 的数据，即驻留集大小（也称为
    RSS，这是进程消耗的内存页数）
    可能仍然在5GB左右，即使Redis会声称用户
    内存约为3GB。 发生这种情况是因为基础分配器无法轻松释放内存。
    例如，通常大多数已删除的密钥都与仍然存在的其他密钥分配在同一页面中。
*   上一点意味着您需要根据
    **峰值内存使用量**.如果您的工作负载不时需要 10GB，即使
    大多数情况下，5GB可以做到，您需要预置10GB。
*   然而，分配器是聪明的，能够重用空闲的内存块，
    因此，在您释放了2GB的5GB数据集后，当您开始添加更多键时
    同样，您将看到RSS（驻留集大小）保持稳定并且不会增长
    更多，因为您最多可以添加2GB的额外密钥。分配器基本上是
    尝试重用以前（逻辑上）释放的2GB内存。
*   由于所有这些，当您
    内存使用率在峰值远大于当前使用的内存。
    碎片计算为实际使用的物理内存（RSS
    value） 除以当前正在使用的内存量（作为所有内存的总和）
    由 Redis 执行的分配）。因为 RSS 反映了峰值内存，
    当（虚拟）使用的内存较低时，因为很多键/值都是
    释放，但RSS高，比率`RSS / mem_used`会很高。

如果`maxmemory`未设置 Redis 将继续分配内存，因为它看到
适合，因此它可以（逐渐）消耗掉你所有的空闲记忆。
因此，通常建议配置一些限制。您也可以
想要设置`maxmemory-policy`自`noeviction`（这是*不*默认值
值在一些旧版本的 Redis 中）。

它使 Redis 在写入命令返回内存不足错误时，如果它到达
限制 - 这反过来可能导致应用程序中的错误，但不会呈现
整台机器因为内存匮乏而死亡。

***

标题： 使用 Redis 集群进行扩展
链接标题： 缩放
体重： 1
描述： 使用 Redis 集群进行水平扩展
别名：

*   /topics/cluster-tutorial
*   /主题/分区

***

Redis 使用称为 Redis Cluster 的部署拓扑进行水平扩展。

本文档对 Redis Cluster 进行了温和的介绍，教您
如何在生产环境中设置、测试和操作 Redis 集群。

本教程还介绍了可用性
从角度看 Redis 集群的一致性特征
的最终用户，以简单易懂的方式陈述。

如果您计划运行生产 Redis 集群部署，或者想要更好地了解 Redis 集群的内部工作原理，请查阅[Redis 集群规范](/topics/cluster-spec).

## Redis Cluster 101

Redis Cluster 提供了一种运行 Redis 安装的方法，其中数据
**跨多个 Redis 节点自动分片**.

Redis Cluster 还提供**分区期间的可用性达到一定程度**,
实际上，这是在以下情况下继续操作的能力：
某些节点出现故障或无法通信。但是，群集停止
在发生较大故障时运行（例如，当大多数
主数据库不可用）。

那么实际上，您从 Redis Cluster 中得到了什么？

*   能够**在多个节点之间自动拆分数据集**.
*   能够**当一部分节点遇到故障时继续操作**或无法与群集的其余部分通信。

### Redis Cluster TCP 端口

每个 Redis 集群节点都需要两个开放的 TCP 连接：一个 Redis
用于为客户端提供服务的 TCP 端口，例如 6379，以及称为
群集总线端口。默认情况下，群集总线端口是通过向数据端口添加10000（例如，16379）来设置的;但是，您可以在`cluster-port`配置。

第二个端口用于群集总线，即节点到节点
使用二进制协议的通信通道。群集总线由
用于故障检测、配置更新、故障转移授权、
等等。客户端不应尝试与群集总线通信
端口，但始终使用正常的 Redis 命令端口，但请确保您
在防火墙中打开两个端口，否则 Redis 群集节点将
无法沟通。

请注意，要使 Redis 集群正常工作，您需要为每个节点执行以下操作：

1.  用于与客户端通信的正常客户端通信端口（通常为 6379）向需要访问群集的所有客户端以及所有其他群集节点（使用客户端端口进行密钥迁移）开放。
2.  群集总线端口必须可从所有其他群集节点访问。

如果不同时打开两个 TCP 端口，群集将无法按预期工作。

群集总线对节点到节点数据使用不同的二进制协议
交换，它更适合于在节点之间交换信息，使用
带宽和处理时间短。

### Redis Cluster 和 Docker

目前，Redis Cluster 不支持 NATted 环境，并且一般情况下
重新映射 IP 地址或 TCP 端口的环境。

Docker 使用一种称为*端口映射*：在 Docker 中运行的程序
容器可能暴露在不同的端口上，而容器的端口
程序认为正在使用。这对于运行多个
容器在同一服务器中同时使用相同的端口。

要使 Docker 与 Redis 集群兼容，您需要使用
Docker's**主机网络模式**.请参阅`--net=host`选择
在[Docker 文档](https://docs.docker.com/engine/userguide/networking/dockernetworks/)了解更多信息。

### Redis 集群数据分片

Redis 集群不使用一致的哈希，而是使用不同形式的分片
其中每个键在概念上都是我们称之为**哈希槽**.

Redis 集群中有 16384 个哈希槽，用于计算哈希
给定密钥的插槽，我们只需取密钥模数的CRC16
16384\.

Redis 集群中的每个节点都负责哈希槽的子集，
因此，例如，您可能有一个包含 3 个节点的群集，其中：

*   节点 A 包含从 0 到 5500 的哈希槽。
*   节点 B 包含从 5501 到 11000 的哈希槽。
*   节点 C 包含从 11001 到 16383 的哈希槽。

这样可以轻松添加和删除群集节点。例如，如果
我想添加一个新的节点D，我需要从节点A，B，C移动一些哈希插槽
到 D。同样，如果我想从群集中删除节点 A，我可以只
将 A 提供的哈希槽移动到 B 和 C。一旦节点 A 为空，
我可以将其从群集中完全删除。

将哈希槽从一个节点移动到另一个节点不需要停止
任何操作;因此，添加和删除节点或更改节点持有的哈希槽的百分比不需要停机。

Redis 集群支持多个密钥操作，只要单个命令执行（或整个事务或 Lua 脚本）中涉及的所有密钥即可
执行） 属于同一哈希槽。用户可以强制多个键
通过使用名为*哈希标签*.

哈希标签记录在 Redis 集群规范中，但要点是
如果键中的 {} 括号之间有子字符串，则只有
在字符串内进行哈希处理。例如，键`user:{123}:profile`和`user:{123}:account`保证位于同一哈希槽中，因为它们共享相同的哈希标记。因此，您可以在相同的多键操作中对这两个键进行操作。

### Redis 集群主副本模型

在主节点子集发生故障或正在发生故障时保持可用
无法与大多数节点通信，Redis 集群使用
主副本模型，其中每个哈希槽具有从 1（主节点本身）到 N 的
副本（N-1 个附加副本节点）。

在我们的示例群集中，节点 A、B、C，如果节点 B 出现故障，则群集不是
能够继续，因为我们不再有办法在
范围 5501-11000。

但是，在创建群集时（或稍后），我们会添加副本
节点到每个主节点，使最终集群由A、B、C组成
是主节点，A1、B1、C1 是副本节点。
这样，如果节点 B 出现故障，系统可以继续。

节点 B1 复制 B，而 B 发生故障，群集会将节点 B1 提升为新的
掌握并将继续正常运行。

但是，请注意，如果节点 B 和 B1 同时发生故障，Redis 集群将无法继续运行。

### Redis 集群一致性保证

Redis 集群不保证**一致性强**.在实践中
这意味着在某些情况下，Redis
群集将丢失系统已确认的写入客户端的写入操作。

Redis Cluster 可能丢失写入操作的第一个原因是因为它使用
异步复制。这意味着在写入期间执行以下操作
发生：

*   您的客户写入主 B。
*   主 B 向您的客户回复 OK。
*   主 B 将写入内容传播到其副本 B1、B2 和 B3。

如您所见，B 不会等待 B1、B2、B3 的确认
回复客户端，因为这将是一个令人望而却步的延迟惩罚
对于 Redis，所以如果你的客户写了一些东西，B 承认了写，
但在能够将写入发送到其副本之前崩溃，其中一个
副本（未收到写入）可以提升为主副本，但会丢失
永远写。

这是**与发生的事情非常相似**对于大多数数据库，这些数据库是
配置为每秒将数据刷新到磁盘，因此这是一个方案
已经能够推理，因为过去与传统的经验
不涉及分布式系统的数据库系统。同样，您可以
通过强制数据库在之前将数据刷新到磁盘来提高一致性
回复客户端，但这通常会导致过低
性能。这相当于 同步复制
Redis Cluster的情况。

基本上，需要在性能和一致性之间进行权衡。

Redis 集群在绝对需要时支持同步写入，
通过`WAIT`命令。这使得丢失的写入大大减少
可能。但是，请注意，Redis 集群没有实现强一致性
即使使用同步复制：它总是可能的，在更多
复杂的故障场景，即副本无法接收写入
将被选为主人。

还有另一个值得注意的场景，Redis集群将丢失写入，即
在网络分区期间发生，其中客户端与少数客户端隔离
的实例数，至少包括一个主实例。

以我们的6节点集群为例，由A，B，C，A1，B1，C1，
具有 3 个主节点和 3 个副本。还有一个客户端，我们称之为 Z1。

分区发生后，有可能在
分区我们有A，C，A1，B1，C1，在另一边我们有B和Z1。

Z1 仍然能够写入 B，B 将接受其写入。如果
分区在很短的时间内愈合，群集将正常继续。
但是，如果分区持续的时间足够长，以便将 B1 提升为主分区
在分区的多数端，Z1 已发送到 B 的写入
在此期间将丢失。

请注意，有一个**最大窗口**到 Z1 将能够的写入量
发送到 B：如果为
分区以选择一个副本作为主节点，每个主节点在少数
side 将停止接受写入。

这个时间量是Redis非常重要的配置指令
群集，并称为**节点超时**.

节点超时后，主节点被视为出现故障，
并且可以由其副本之一替换。
同样，在节点超时过去后，主节点无法
要感知大多数其他主节点，它将进入错误状态
并停止接受写入。

## Redis 集群配置参数

我们将创建一个示例群集部署。在我们继续之前，
我们来介绍一下 Redis 集群引入的配置参数
在`redis.conf`文件。

*   **已启用群集`<yes/no>`**：如果是，请在特定 Redis 实例中启用 Redis 集群支持。否则，实例将像往常一样作为独立实例启动。
*   **群集配置文件`<filename>`**：请注意，尽管此选项的名称，但这不是用户可编辑的配置文件，而是 Redis 集群节点在每次发生更改时自动保留集群配置（基本上是状态）的文件，以便能够在启动时重新读取它。该文件列出了群集中的其他节点、其状态、持久性变量等内容。通常，由于某些消息接收，此文件会被重写并在磁盘上刷新。
*   **群集节点超时`<milliseconds>`**：Redis 集群节点不可用的最长时间，而不会将其视为失败。如果无法访问主节点的时间超过指定的时间量，则其副本将对其进行故障转移。此参数控制 Redis 集群中的其他重要事项。值得注意的是，在指定时间内无法访问大多数主节点的每个节点都将停止接受查询。
*   **集群从站有效性因子`<factor>`**：如果设置为零，则副本将始终认为自己有效，因此将始终尝试故障转移主节点，而不管主服务器和副本服务器之间的链路断开连接的时间长短。如果该值为正，则最大断开连接时间计算为*节点超时*值乘以此选项提供的因子，如果节点是副本，则当主链路断开连接的时间超过指定时间时，它不会尝试启动故障转移。例如，如果节点超时设置为 5 秒，有效性因子设置为 10，则与主节点断开连接超过 50 秒的副本将不会尝试故障转移其主节点。请注意，如果没有能够故障转移的副本，则任何值都可能导致 Redis 集群在主故障后不可用。在这种情况下，仅当原始主服务器重新加入群集时，群集才会恢复可用。
*   **集群迁移屏障`<count>`**：主副本将与之保持连接的最小数量，以便另一个副本迁移到不再被任何副本覆盖的主副本。有关详细信息，请参阅本教程中有关副本迁移的相应部分。
*   **集群要求完全覆盖`<yes/no>`**：如果此值设置为 yes（默认情况下），则当任何节点未覆盖某个百分比的密钥空间时，群集将停止接受写入。如果该选项设置为 no，则即使只能处理有关键子集的请求，群集仍将为查询提供服务。
*   **群集允许读取时关闭`<yes/no>`**：如果设置为 no（默认情况下），则 Redis 集群中的节点将在集群被标记为失败时停止为所有流量提供服务，无论是当节点无法达到主节点仲裁还是未达到完全覆盖时。这可以防止从不知道群集中更改的节点读取可能不一致的数据。此选项可以设置为 yes 以允许在失败状态期间从节点读取，这对于希望确定读取可用性优先级但仍希望防止不一致写入的应用程序非常有用。当使用只有一个或两个分片的 Redis 集群时，它也可以使用它，因为它允许节点在主节点发生故障但无法自动故障转移时继续提供写入服务。

## 创建和使用 Redis 集群

要创建集群，我们需要做的第一件事就是有一些空的集群。
运行在 中的 Redis 实例**集群模式**.

至少，您将在`redis.conf`文件：

    port 7000
    cluster-enabled yes
    cluster-config-file nodes.conf
    cluster-node-timeout 5000
    appendonly yes

设置`cluster-enabled`指令`yes`启用群集模式。
每个实例还包含文件的路径，其中
存储此节点的配置，默认情况下为`nodes.conf`.
此文件永远不会被人类触及;它只是在启动时生成
由 Redis 集群实例提供，并在每次需要时进行更新。

请注意，**最小集群**按预期工作必须包含
至少三个主节点。对于部署，我们强烈建议
一个六节点群集，具有三个主节点和三个副本。

您可以通过创建以下名为
在实例的端口号之后，您将在任何给定的目录中运行。

例如：

    mkdir cluster-test
    cd cluster-test
    mkdir 7000 7001 7002 7003 7004 7005

创建一个`redis.conf`文件，从 7000 到 7005。
作为配置文件的模板，只需使用上面的小示例，
但请确保替换端口号`7000`具有正确的端口号
根据目录名称。

您可以按如下方式启动每个实例，每个实例在单独的终端选项卡中运行：

    cd 7000
    redis-server ./redis.conf

您将从日志中看到，每个节点都为自己分配了一个新 ID：

    [82462] 26 Nov 11:56:55.329 * No cluster configuration found, I'm 97a3a64667477371c4479320d683e4c8db5858b1

此特定实例将永久使用此 ID，以便用于该实例
以在群集的上下文中具有唯一的名称。每个节点
记住使用此 ID 的所有其他节点，而不是按 IP 或端口。
IP 地址和端口可能会更改，但唯一节点标识符永远不会更改
更改节点的所有生命周期。我们简单地称此标识符为**节点标识**.

### 初始化集群

现在我们已经运行了许多实例，我们需要创建
通过向节点写入一些有意义的配置来群集。

要创建集群，请运行：

    redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \
    127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \
    --cluster-replicas 1

此处使用的命令是**创造**，因为我们想要创建一个新的集群。
选项`--cluster-replicas 1`意味着我们需要为每个创建的主站创建一个副本。

其他参数是我想使用的实例的地址列表
以创建新群集。

`redis-cli`将提出一个配置。通过键入**是的**.
将配置群集并*加入*，这意味着实例将是
自力更生地互相交谈。最后，如果一切顺利，您将看到如下消息：

    [OK] All 16384 slots covered

这意味着至少有一个主实例为
16384 个可用插槽。

### 使用创建集群脚本创建 Redis 集群

如果您不想通过配置和执行来创建 Redis 集群
如上所述，手动处理单个实例，有一个更简单的实例
系统（但你不会学到相同数量的操作细节）。

找到`utils/create-cluster`目录。
有一个脚本叫做`create-cluster`内部（与目录同名
它包含在），这是一个简单的bash脚本。为了开始
具有 3 个主节点和 3 个副本的 6 节点群集只需键入以下内容
命令：

1.  `create-cluster start`
2.  `create-cluster create`

回复`yes`在步骤 2 中，当`redis-cli`实用程序希望您接受
群集布局。

您现在可以与群集交互，第一个节点将从端口 30001 开始
默认情况下。完成后，使用以下命令停止群集：

3.  `create-cluster stop`

请阅读`README`中，了解有关如何
以运行脚本。

### 与集互

***

要连接到 Redis 集群，您需要一个支持集群的 Redis 客户端。请参阅所选客户端的文档以确定其群集支持。

您还可以使用`redis-cli`命令行实用程序：

    $ redis-cli -c -p 7000
    redis 127.0.0.1:7000> set foo bar
    -> Redirected to slot [12182] located at 127.0.0.1:7002
    OK
    redis 127.0.0.1:7002> set hello world
    -> Redirected to slot [866] located at 127.0.0.1:7000
    OK
    redis 127.0.0.1:7000> get foo
    -> Redirected to slot [12182] located at 127.0.0.1:7002
    "bar"
    redis 127.0.0.1:7002> get hello
    -> Redirected to slot [866] located at 127.0.0.1:7000
    "world"

**注意：**如果使用脚本创建了群集，则节点可能会侦听
在不同的端口上，默认情况下从 30001 开始。

这`redis-cli`集群支持是非常基本的，所以它总是使用这样一个事实：
Redis 群集节点能够将客户端重定向到正确的节点。
一个认真的客户端能够做得更好，并在两者之间缓存地图
哈希槽和节点地址，直接使用正确的连接
右节点。仅当群集中发生更改时，才会刷新映射
配置，例如在故障转移之后或系统管理员之后
通过添加或删除节点更改了群集布局。

### 使用 redis-rb-cluster 编写示例应用

在继续展示如何操作 Redis 集群之前，请先做事
就像故障转移或重新分片一样，我们需要创建一些示例应用程序
或者至少能够理解一个简单的 Redis 集群的语义
客户端交互。

通过这种方式，我们可以运行一个示例，同时尝试创建节点。
失败，或启动重新分片，以查看 Redis 集群在真实情况下的行为
世界条件。在没有人的情况下看到会发生什么并不是很有帮助
正在写入群集。

本节介绍 一些基本用法
[redis-rb-cluster](https://github.com/antirez/redis-rb-cluster)显示两个
例子。第一个是以下，并且是
[`example.rb`](https://github.com/antirez/redis-rb-cluster/blob/master/example.rb)
文件在 redis-rb-cluster distribution 中：

       1  require './cluster'
       2
       3  if ARGV.length != 2
       4      startup_nodes = [
       5          {:host => "127.0.0.1", :port => 7000},
       6          {:host => "127.0.0.1", :port => 7001}
       7      ]
       8  else
       9      startup_nodes = [
      10          {:host => ARGV[0], :port => ARGV[1].to_i}
      11      ]
      12  end
      13
      14  rc = RedisCluster.new(startup_nodes,32,:timeout => 0.1)
      15
      16  last = false
      17
      18  while not last
      19      begin
      20          last = rc.get("__last__")
      21          last = 0 if !last
      22      rescue => e
      23          puts "error #{e.to_s}"
      24          sleep 1
      25      end
      26  end
      27
      28  ((last.to_i+1)..1000000000).each{|x|
      29      begin
      30          rc.set("foo#{x}",x)
      31          puts rc.get("foo#{x}")
      32          rc.set("__last__",x)
      33      rescue => e
      34          puts "error #{e.to_s}"
      35      end
      36      sleep 0.1
      37  }

该应用程序做了一件非常简单的事情，它在表单中设置键`foo<number>`自`number`，一个接一个。因此，如果您运行该程序，则结果是
以下命令流：

*   设置 foo0 0
*   设置 foo1 1
*   设置 foo2 2
*   等等...

该程序看起来比通常应该的更复杂，因为它的设计
在屏幕上显示错误，而不是异常退出，因此每个
对群集执行的操作包装为`begin` `rescue`块。

这**14号线**是程序中第一个有趣的行。它创建了
Redis 群集对象，使用列表作为参数*启动节点*，最大值
允许此对象对不同节点采取的连接数，
最后，给定操作后的超时被视为失败。

启动节点不必是群集的所有节点。重要
事情是至少有一个节点是可访问的。另请注意，redis-rb-cluster
更新此启动节点列表，只要它能够连接到
第一个节点。您应该期望任何其他严肃的客户端都有这样的行为。

现在我们已经将 Redis 集群对象实例存储在**钢筋混凝土**变量
我们准备使用该对象，就像它是一个普通的Redis对象实例一样。

这正是在**第 18 至 26 行**：当我们重新启动示例时
我们不想重新开始`foo0`，所以我们把柜台存放在里面
Redis本身。上面的代码旨在读取此计数器，或者如果
计数器不存在，为其分配值为零。

但是请注意，这是一个while循环，因为我们想要一次又一次地尝试
如果群集已关闭并返回错误。普通应用程序不需要
要小心。

**28 和 37 之间的线路**启动设置按键的主循环，或者
显示错误。

请注意`sleep`在循环结束时调用。在测试中，您可以删除
睡眠，如果你想尽快写入集群（相对而言）
当然，这是一个没有真正并行性的繁忙循环，所以
在最佳条件下，您将获得通常的10k操作/秒）。

通常，写入速度会减慢，以便示例应用程序
更容易被人类遵循。

启动应用程序将生成以下输出：

    ruby ./example.rb
    1
    2
    3
    4
    5
    6
    7
    8
    9
    ^C (I stopped the program here)

这不是一个非常有趣的程序，我们稍后会使用一个更好的程序。
但是我们已经可以看到在重新分片期间程序会发生什么
正在运行。

### 重新分片集群

现在，我们已准备好尝试集群重新分片。为此，请
保持 example.rb 程序运行，以便您可以查看是否有
对正在运行的程序的影响。此外，您可能还想评论`sleep`
调用，以便在重新分片期间有一些更严重的写入负载。

重新分片基本上意味着将哈希槽从一组节点移动到另一组节点
节点集，与群集创建一样，它是使用
redis-cli utility.

要开始重新分片，只需键入：

    redis-cli --cluster reshard 127.0.0.1:7000

你只需要指定一个节点，redis-cli就会找到其他节点
自然而然。

目前，redis-cli 只能在管理员支持下重新分片，
你不能只是说将5%的插槽从这个节点移动到另一个节点（但是
这是非常微不足道的实现）。所以它从问题开始。第一个
是您要执行多少重新分片：

    How many slots do you want to move (from 1 to 16384)?

我们可以尝试重新分片 1000 个哈希槽，这些槽应该已经包含一个非
如果示例在没有休眠的情况下仍在运行，则键数量微不足道
叫。

然后，redis-cli 需要知道重新分片的目标是什么，即
将接收哈希槽的节点。
我将使用第一个主节点，即 127.0.0.1：7000，但我需要
以指定实例的节点 ID。这已经打印在
列表 by redis-cli，但我始终可以找到具有以下特性的节点的 ID
命令，如果我需要：

    $ redis-cli -p 7000 cluster nodes | grep myself
    97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5460

好的，所以我的目标节点是97a3a64667477371c4479320d683e4c8db5858b1。

现在，系统将询问您要从哪些节点获取这些密钥。
我只需键入`all`为了从所有
其他主节点。

最终确认后，您将看到每个插槽的消息
redis-cli 将从一个节点移动到另一个节点，并且将打印一个点
对于从一侧移动到另一侧的每个实际密钥。

在重新分片过程中，您应该能够看到您的
示例程序运行不受影响。您可以多次停止和重新启动它
如果需要，在重新分片期间。

在重新分片结束时，您可以使用
以下命令：

    redis-cli --cluster check 127.0.0.1:7000

所有插槽将像往常一样被覆盖，但这次主控
127.0.0.1：7000 将有更多的哈希槽，大约在 6461 左右。

### 编写重新分片操作的脚本

可以自动执行重新分片，无需手动
以交互方式输入参数。使用命令可以做到这一点
行如下所示：

    redis-cli --cluster reshard <host>:<port> --cluster-from <node-id> --cluster-to <node-id> --cluster-slots <number of slots> --cluster-yes

这允许建立一些自动化，如果你可能经常重新分片，
但是目前没有办法`redis-cli`自动
重新平衡群集，检查密钥在群集中的分布
节点，并根据需要智能移动插槽。将添加此功能
在未来。

这`--cluster-yes`选项指示集群管理器自动应答
命令提示符为“yes”，允许它在非交互模式下运行。
请注意，也可以通过设置
`REDISCLI_CLUSTER_YES`环境变量。

### 一个更有趣的示例应用程序

我们之前编写的示例应用程序不是很好。
它以简单的方式写入集群，甚至无需检查是否是什么
写是正确的事情。

从我们的角度来看，接收写入的集群可以始终
写入密钥`foo`自`42`到每个操作，我们不会注意到
都。

所以在`redis-rb-cluster`存储库，还有一个更有趣的应用程序
这称为`consistency-test.rb`.它使用一组计数器（默认为 1000），并发送`INCR`命令以递增计数器。

但是，应用程序不只是编写，而是执行另外两项操作：

*   当使用更新计数器时`INCR`，应用程序会记住写入。
*   它还在每次写入之前读取一个随机计数器，并检查该值是否与我们预期的值进行比较，并将其与内存中的值进行比较。

这意味着这个应用程序是一个简单的**一致性检查器**,
并能够告诉您集群是否丢失了一些写入，或者它是否被接受
我们没有收到确认的书面内容。在第一种情况下，我们将
看到一个计数器的值小于我们记忆中的值，而
在第二种情况下，该值将更大。

运行一致性测试应用程序会每隔一次生成一行输出
第二：

    $ ruby consistency-test.rb
    925 R (0 err) | 925 W (0 err) |
    5030 R (0 err) | 5030 W (0 err) |
    9261 R (0 err) | 9261 W (0 err) |
    13517 R (0 err) | 13517 W (0 err) |
    17780 R (0 err) | 17780 W (0 err) |
    22025 R (0 err) | 22025 W (0 err) |
    25818 R (0 err) | 25818 W (0 err) |

该行显示的编号**R**eads 和**W**执行的仪式，以及
错误数（由于系统
不可用）。

如果发现某些不一致，则会向输出中添加新行。
例如，如果我手动重置计数器，而
程序正在运行：

    $ redis-cli -h 127.0.0.1 -p 7000 set key_217 0
    OK

    (in the other tab I see...)

    94774 R (0 err) | 94774 W (0 err) |
    98821 R (0 err) | 98821 W (0 err) |
    102886 R (0 err) | 102886 W (0 err) | 114 lost |
    107046 R (0 err) | 107046 W (0 err) | 114 lost |

当我将计数器设置为0时，实际值为114，因此程序报告
114 个丢失的写入 （`INCR`群集不记得的命令）。

作为测试用例，这个程序更有趣，所以我们将使用它。
以测试 Redis 群集故障转移。

## 测试故障转移

注意：在此测试期间，您应该打开一个带有一致性测试的选项卡
应用程序正在运行。

为了触发故障转移，我们可以做的最简单的事情（也是
在分布式系统中可能发生的语义上最简单的故障）
就是崩溃单个进程，在我们的例子中是单个主进程。

我们可以识别一个主节点，并使用以下命令将其崩溃：

    $ redis-cli -p 7000 cluster nodes | grep master
    3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385482984082 0 connected 5960-10921
    2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 master - 0 1385482983582 0 connected 11423-16383
    97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-11422

好的，所以7000，7001和7002是主。让我们将节点 7002 与
**调试 SEGFAULT**命令：

    $ redis-cli -p 7002 debug segfault
    Error: Server closed the connection

现在我们可以查看一致性测试的输出，看看它报告了什么。

    18849 R (0 err) | 18849 W (0 err) |
    23151 R (0 err) | 23151 W (0 err) |
    27302 R (0 err) | 27302 W (0 err) |

    ... many error warnings here ...

    29659 R (578 err) | 29660 W (577 err) |
    33749 R (578 err) | 33750 W (577 err) |
    37918 R (578 err) | 37919 W (577 err) |
    42077 R (578 err) | 42078 W (577 err) |

正如您在故障转移期间所看到的，系统无法接受 578 次读取和 577 次写入，但是数据库中没有造成不一致。这可能
听起来出乎意料，因为在本教程的第一部分中，我们说过Redis
群集可能会在故障转移期间丢失写入操作，因为它使用异步
复制。我们没有说的是，这不太可能发生。
因为 Redis 将回复发送到客户端，以及要复制的命令
到复制品，大约在同一时间，所以有一个非常小的窗口
丢失数据。然而，它很难触发的事实并不意味着它
是不可能的，所以这不会改变提供的一致性保证
由 Redis cluster 提供。

现在，我们可以检查故障转移后的群集设置（请注意
在此期间，我重新启动了崩溃的实例，以便它重新加入
群集作为副本）：

    $ redis-cli -p 7000 cluster nodes
    3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385503418521 0 connected
    a211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385503419023 0 connected
    97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-11422
    3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385503419023 3 connected 11423-16383
    3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385503417005 0 connected 5960-10921
    2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385503418016 3 connected

现在，主服务器在端口 7000、7001 和 7005 上运行。以前是什么
主节点（即在端口 7002 上运行的 Redis 实例）现在是
7005\.

的输出`CLUSTER NODES`命令可能看起来令人生畏，但它实际上非常简单，并且由以下标记组成：

*   节点标识
*   ip：端口
*   标志：主，副本，我自己，失败，...
*   如果是副本，则主节点的节点 ID
*   上次挂起的 PING 仍在等待答复的时间。
*   收到最后一次 PONG 的时间。
*   此节点的配置纪元（请参阅群集规范）。
*   指向此节点的链接的状态。
*   插槽服务...

### 手动故障转移

有时，在不实际导致任何问题的情况下强制故障转移很有用
在主站上。例如，为了升级 Redis 进程之一
主节点 最好对其进行故障转移，以便将其转换为副本
对可用性的影响最小。

Redis 集群支持手动故障转移，使用`CLUSTER FAILOVER`
命令，必须在**副本**您想要的主人
以进行故障转移。

手动故障转移是特殊的，与以下原因导致的故障转移相比更安全
实际的主故障，因为它们的发生方式可以避免数据丢失
进程，通过将客户端从原始主服务器切换到新主服务器
当系统确定新主服务器处理了所有复制流时
从旧的。

以下是您在执行手动故障转移时在副本日志中看到的内容：

    # Manual failover user request accepted.
    # Received replication offset for paused master manual failover: 347540
    # All master replication stream processed, manual failover can start.
    # Start of election delayed for 0 milliseconds (rank #0, offset 347540).
    # Starting a failover election for epoch 7545.
    # Failover election won: I'm the new master.

基本上，连接到我们要故障转移的主节点的客户端已停止。
同时，主服务器将其复制偏移量发送到副本，
等待到达其一侧的偏移量。当达到复制偏移量时，
故障转移开始，并通知旧主服务器有关配置的信息
开关。当客户端在旧主服务器上解除阻止时，它们将被重定向
添加到新主节点。

注意：

*   要将副本提升为主副本，必须首先将其由群集中的大多数主服务器称为副本。
    否则，它无法赢得故障转移选举。
    如果副本刚刚添加到群集（请参阅[将新节点添加为副本](#adding-a-new-node-as-a-replica)下面），您可能需要等待一段时间才能发送`CLUSTER FAILOVER`命令，以确保群集中的主节点知道新的复制副本。

### 添加新节点

添加新节点基本上是添加空节点的过程，然后
将一些数据移动到其中，以防它是一个新的主数据，或者告诉它
设置为已知节点的副本，以防它是副本。

我们将展示两者，从添加新的主实例开始。

在这两种情况下，执行的第一步是**添加空节点**.

这就像在端口7006中启动新节点一样简单（我们已经使用了
对于我们现有的 6 个节点，从 7000 到 7005），具有相同的配置
用于其他节点，除了端口号，所以你应该做什么
do 为了符合我们为前面的节点使用的设置：

*   在终端应用程序中创建一个新选项卡。
*   输入`cluster-test`目录。
*   创建一个名为`7006`.
*   在内部创建一个 redis.conf 文件，类似于用于其他节点的文件，但使用 7006 作为端口号。
*   最后启动服务器`../redis-server ./redis.conf`

此时，服务器应正在运行。

现在我们可以使用**redis-cli**像往常一样，以便将节点添加到
现有群集。

    redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000

如您所见，我使用了**添加节点**命令指定
new node 作为第一个参数，以及
聚类作为第二个参数。

实际上，redis-cli在这里几乎没有帮助我们，它只是
发送了`CLUSTER MEET`向节点发送消息，这也是可能的
以手动完成。但是，redis-cli 也会检查
群集之前要操作，因此最好执行群集操作
总是通过redis-cli，即使你知道内部是如何工作的。

现在我们可以连接到新节点，看看它是否真的加入了集群：

    redis 127.0.0.1:7006> cluster nodes
    3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385543178575 0 connected 5960-10921
    3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385543179583 0 connected
    f093c80dde814da99c5cf72a7dd01590792b783b :0 myself,master - 0 0 0 connected
    2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543178072 3 connected
    a211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385543178575 0 connected
    97a3a64667477371c4479320d683e4c8db5858b1 127.0.0.1:7000 master - 0 1385543179080 0 connected 0-5959 10922-11422
    3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385543177568 3 connected 11423-16383

请注意，由于此节点已连接到群集，因此它已
能够正确重定向客户端查询，并且通常说是
群集。然而，与其他大师相比，它有两个特点：

*   它不保存任何数据，因为它没有分配的哈希槽。
*   由于它是没有分配槽位的主节点，因此当副本想要成为主服务器时，它不会参与选举过程。

现在，可以使用重新分片将哈希槽分配给此节点
特点`redis-cli`.显示这一点基本上是无用的，因为我们已经
在上一节中做了，没有区别，只是重新分片
以空节点为目标。

### 将新节点添加为副本

可以通过两种方式添加新副本。显而易见的一个是
再次使用 redis-cli，但使用 --cluster-slave 选项，如下所示：

    redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-slave

请注意，此处的命令行与我们过去添加的命令行完全相同
一个新的主控形状，所以我们没有指定要添加到哪个主控
复制副本。在这种情况下，发生的事情是redis-cli将添加新的
节点作为具有较少副本的主节点中的随机主节点的副本。

但是，您可以准确指定要针对的主控形状
使用以下命令行新建副本：

    redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-slave --cluster-master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e

这样，我们将新副本分配给特定的主副本。

将副本添加到特定主副本的一种更手动的方法是添加新的
节点作为空主节点，然后使用
`CLUSTER REPLICATE`命令。如果节点已添加为副本，这也有效
但您希望将其作为其他主节点的副本进行移动。

例如，为了为节点 127.0.0.1：7005 添加副本，即
当前为 11423-16383 范围内具有节点 ID 的哈希槽提供服务
3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e，我需要做的就是连接
使用新节点（已添加为空主节点）并发送命令：

    redis 127.0.0.1:7006> cluster replicate 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e

就是这样。现在，我们有了这组哈希槽的新副本，并且所有
群集中的其他节点已经知道（几秒钟后需要
更新他们的配置）。我们可以使用以下命令进行验证：

    $ redis-cli -p 7000 cluster nodes | grep slave | grep 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e
    f093c80dde814da99c5cf72a7dd01590792b783b 127.0.0.1:7006 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543617702 3 connected
    2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543617198 3 connected

节点 3c3a0c...现在有两个副本，在端口 7002（现有副本）和 7006 端口（新副本）上运行。

## 删除节点

要删除副本节点，只需使用`del-node`redis-cli 的命令：

    redis-cli --cluster del-node 127.0.0.1:7000 `<node-id>`

第一个参数只是集群中的随机节点，第二个参数
是要删除的节点的 ID。

您也可以以相同的方式删除主节点，**但是为了
删除主节点，它必须为空**.如果主节点不为空，则需要
将数据从它重新分片到之前的所有其他主节点。

删除主节点的另一种方法是对其执行手动故障转移
在其一个副本上，并在节点变为
新主控。显然，当您想要减少实际值时，这无济于事
集群中的主节点数，在这种情况下，需要重新分片。

### 副本迁移

在 Redis 集群中，可以重新配置副本以使用
不同的主节点随时只需使用以下命令：

    CLUSTER REPLICATE <master-node-id>

但是，有一种特殊情况，您希望副本从一个副本移动
主站自动到另一个，无需系统管理员的帮助。
副本的自动重新配置称为*副本迁移*并且是
能够提高 Redis 集群的可靠性。

注意：您可以在[Redis 集群规范](/topics/cluster-spec)，在这里我们只提供一些关于
一般的想法以及您应该做些什么才能从中受益。

您可能希望让群集副本从一个主节点移动的原因
在一定条件下的另一个，是通常Redis集群是
可抵抗故障，因为附加到给定主服务器的副本数。

例如，每个主节点都有一个副本的集群无法继续
如果主服务器及其复制副本同时发生故障，则操作，原因很简单
没有其他实例可以拥有主节点的哈希槽的副本
服务。然而，虽然网络拆分可能会隔离许多节点
同时，还有许多其他类型的故障，如硬件或软件故障
本地到单个节点，是一类非常值得注意的故障，不太可能
同时发生，因此在您的集群中，有可能
每个主站都有一个副本，副本在凌晨4点被杀死，主站被杀死
早上6点。这仍然会导致集群无法再运行。

为了提高系统的可靠性，我们可以选择添加额外的
复制到每个主站，但这很昂贵。副本迁移允许
将更多副本添加到几个主节点。所以你有10个主站和1个副本
每个实例，总共 20 个实例。但是，例如，您添加 3 个实例
更多作为某些主控形状的副本，因此某些主控器将拥有更多
而不是单个副本。

使用副本迁移时，如果主服务器没有
副本，来自具有多个副本的主节点的副本将迁移到
这*孤*主人。因此，在复制副本在凌晨 4 点关闭后，如示例中所示
我们做了上面，另一个复制品将取而代之，而当主人
在凌晨5点也会失败，仍然有一个副本可以选择，以便
群集可以继续运行。

那么，关于副本迁移，您应该了解哪些内容呢？

*   群集将尝试从在给定时刻具有最多副本的主服务器迁移副本。
*   要从副本迁移中受益，您只需向群集中的单个主节点再添加几个副本，那么什么主节点并不重要。
*   有一个配置参数用于控制副本迁移功能，该参数称为`cluster-migration-barrier`：您可以在示例中阅读更多相关信息`redis.conf`随 Redis Cluster 一起提供的文件。

## 升级 Redis 集群中的节点

升级副本节点很容易，因为您只需要停止节点并重新启动
它带有Redis的更新版本。如果有客户端使用缩放读取
副本节点，如果给定
一个不可用。

升级主节点有点复杂，建议的过程是：

1.  用`CLUSTER FAILOVER`以触发主服务器到其副本之一的手动故障转移。
    （请参阅[手动故障转移](#manual-failover)部分。
2.  等待主服务器变成副本。
3.  最后，像升级副本一样升级节点。
4.  如果希望主节点成为刚刚升级的节点，请触发新的手动故障转移，以便将升级后的节点变回主节点。

按照此过程，您应该先于一个节点升级另一个节点，直到
所有节点都已升级。

## 迁移到 Redis 集群

愿意迁移到 Redis 集群的用户可能只有一个主节点，或者
可能已经使用了预先存在的分片设置，其中键
在 N 个节点之间拆分，使用一些内部算法或分片算法
由其客户端库或 Redis 代理实现。

但是，在这两种情况下，都可以轻松迁移到 Redis 集群
最重要的细节是是否使用多键操作
按应用程序，以及如何。有三种不同的情况：

1.  不使用多个密钥操作或事务，或涉及多个密钥的 Lua 脚本。密钥是独立访问的（即使通过事务或 Lua 脚本将多个命令（大约同一个密钥组合在一起）进行访问）。
2.  使用多个密钥操作、事务或涉及多个密钥的 Lua 脚本，但只能使用具有相同密钥的密钥**哈希标记**，这意味着一起使用的密钥都具有`{...}`恰好相同的子字符串。例如，在同一哈希标记的上下文中定义了以下多键操作：`SUNION {user:1000}.foo {user:1000}.bar`.
3.  多个密钥操作、事务或涉及多个密钥的 Lua 脚本与没有显式或相同哈希标记的密钥名称一起使用。

第三种情况不是由 Redis 集群处理的：应用程序需要
进行修改，以便不使用多键操作或仅在
同一哈希标记的上下文。

案例 1 和 2 已涵盖，因此我们将重点介绍已处理的这两个案例
以同样的方式，因此在文档中不会进行任何区分。

假设您将预先存在的数据集拆分为 N 个主节点，其中
N=1 如果没有预先存在的分片，则需要执行以下步骤
为了将您的数据集迁移到 Redis 集群：

1.  停止客户端。目前无法自动实时迁移到 Redis 集群。您可以在应用程序/环境的上下文中协调实时迁移。
2.  使用`BGREWRITEAOF`命令，并等待 AOF 文件完全生成。
3.  将 AOF 文件从 aof-1 保存到 aof-N 的某个位置。此时，如果您愿意，可以停止旧实例（这很有用，因为在非虚拟化部署中，您通常需要重用相同的计算机）。
4.  创建由 N 个主节点和零个副本组成的 Redis 集群。稍后将添加副本。确保所有节点都使用仅追加文件进行持久性。
5.  停止所有群集节点，将其仅追加文件替换为预先存在的仅追加文件，aof-1 表示第一个节点，aof-2 替换为第二个节点，最多 aof-N。
6.  使用新的 AOF 文件重新启动 Redis 集群节点。他们会抱怨有些密钥不应该根据他们的配置而存在。
7.  用`redis-cli --cluster fix`命令，以便根据每个节点是否具有权威性的哈希槽迁移密钥。
8.  用`redis-cli --cluster check`最后，以确保您的集群正常。
9.  重新启动已修改为使用 Redis 集群感知客户端库的客户端。

还有另一种方法可以将数据从外部实例导入 Redis
群集，即使用`redis-cli --cluster import`命令。

该命令移动正在运行的实例的所有密钥 （从中删除密钥
源实例） 添加到指定的预先存在的 Redis 集群。然而
请注意，如果使用 Redis 2.8 实例作为源实例，则操作
可能很慢，因为 2.8 没有实现迁移连接缓存，所以
可能希望在之前使用 Redis 3.x 版本重新启动源实例
以执行此类操作。

**关于本页中使用的“从属”一词的说明**：从 Redis 5 开始，如果不是为了向后兼容，Redis 项目不再使用“从属”一词。不幸的是，在此命令中，单词 slave 是协议的一部分，因此只有当此 API 自然弃用时，我们才能删除此类事件。
